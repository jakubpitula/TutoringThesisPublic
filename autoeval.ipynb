{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bert_score in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: torch>=1.0.0 in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from bert_score) (2.2.1)\n",
      "Requirement already satisfied: pandas>=1.0.1 in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from bert_score) (2.2.0)\n",
      "Requirement already satisfied: transformers>=3.0.0 in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from bert_score) (4.39.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from bert_score) (1.26.4)\n",
      "Requirement already satisfied: requests in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from bert_score) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from bert_score) (4.66.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from bert_score) (3.8.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from bert_score) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from pandas>=1.0.1->bert_score) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from pandas>=1.0.1->bert_score) (2024.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from torch>=1.0.0->bert_score) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from torch>=1.0.0->bert_score) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from torch>=1.0.0->bert_score) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from torch>=1.0.0->bert_score) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from torch>=1.0.0->bert_score) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from torch>=1.0.0->bert_score) (2024.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from tqdm>=4.31.1->bert_score) (0.4.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from transformers>=3.0.0->bert_score) (0.22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from transformers>=3.0.0->bert_score) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from transformers>=3.0.0->bert_score) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from transformers>=3.0.0->bert_score) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from transformers>=3.0.0->bert_score) (0.4.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from matplotlib->bert_score) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from matplotlib->bert_score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from matplotlib->bert_score) (4.48.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from matplotlib->bert_score) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from matplotlib->bert_score) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from matplotlib->bert_score) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from requests->bert_score) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from requests->bert_score) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from requests->bert_score) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from requests->bert_score) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kuba\\onedrive\\pulpit\\studia\\year 4\\thesis\\scripts\\venv\\lib\\site-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install bert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "generations = []\n",
    "references = []\n",
    "contexts = []\n",
    "\n",
    "for filename in ['base_model_out.txt', 'base_model_out_2.txt', 'base_model_out_3.txt', 'base_model_out_4.txt']:\n",
    "    with open(filename, 'r',  encoding=\"utf8\") as f:\n",
    "        context = \"\"\n",
    "        gen = \"\"\n",
    "        long_scaff = False\n",
    "        for line in f.readlines():\n",
    "            if long_scaff:\n",
    "                if '=====================' in line:\n",
    "                    contexts.append(context)\n",
    "                    context = \"\"\n",
    "                    generations.append(gen)\n",
    "                    gen = \"\"\n",
    "                    long_scaff = False\n",
    "                else:\n",
    "                    if line.strip():\n",
    "                        gen += ' ' + line.strip() \n",
    "            else:\n",
    "                if line.split()[:2] == ['ORIGINAL', 'SCAFFOLDING:']:\n",
    "                    references.append(' '.join(line.split()[2:]))\n",
    "                elif line.split()[:2] == ['GENERATED', 'SCAFFOLDING:']:\n",
    "                    gen += (' '.join(line.split()[2:]))\n",
    "                    long_scaff = True\n",
    "                elif line.split()[:1] == ['STUDENT:'] or line.split()[:1] == ['TEACHER:']:\n",
    "                  context += (' '.join(line.split()[1:]) + \"<|endoftext|>\")\n",
    "                elif '=====================' in line:\n",
    "                  contexts.append(context)\n",
    "                  context = \"\"\n",
    "                  generations.append(gen)\n",
    "                  gen = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Sure, it comes with practice! Don't give up. It does take a few tries to get comfortable with the poses and breathing techniques. Try to do 15 minutes per day. You'll get there with persistence and before you know it, you'll see the benefits!\",\n",
       " 'Great! Yoga practice has a lot of benefits. How about your listening and speaking skills? Would you like to practice these using a native English speaker?',\n",
       " 'Yes, practice is another helpful practice to build up your English skills.',\n",
       " \"Oh, you might enjoy this video, but don't try the poses at home, especially not with those IKEA chairs!).\",\n",
       " \"Correct! You got it! 'Have been married' means they were married in the past and are not married now. 'Were married' is the same meaning. Great job! You're learning fast. Keep it up!\",\n",
       " \"Yes, you're warming up! Remember, we can use present perfect for a past action that has an effect on the present.\",\n",
       " 'No. They were once a celebrated couple!',\n",
       " '* propose * introduce * pass * comes into effect * is passed * is introduced',\n",
       " \"...and if the bill gets approved by the Parliament, then it becomes an Act. It's like a law that people have to follow.\",\n",
       " \"That's right! In UK parliamentary jargon, when a proposal is successful in the House of Commons, it 'passes'. In the US, a passed proposal is called a law - so the British would say the bill 'passed', while for Americans, the bill 'becomes a law'.\",\n",
       " 'Great! So, once the bill is passed, it becomes a law. And when the government creates a new law it is called an act, not a bill.',\n",
       " 'The bill passes. If the majority of MPs agree, they pass the bill.',\n",
       " \"That's right! So, when the bill is passed, it becomes a new law.,\",\n",
       " \"That's right! The President signs the bill / signs the new law.\",\n",
       " \"It's the final formality, a rubber stamp. You're doing very well! Can you summarize the process?\",\n",
       " \"It's a check and balance, like in the UK, where the monarch signs the bill but may not agree with it. In both cases, the head of state has to sign. It's a formality, but an important one.\",\n",
       " 'Great! Remember, a good English learner must prioritize grammar precision. Always try to say \"it is better to stop at 3:30\" instead of \"we didn\\'t start on time.\" Grammatically, \"didn\\'t start\" is in the past tense, whereas \"it is better to\" is in the present tense.',\n",
       " 'I see! So, that means you already had a PE lesson before your last lesson, right?',\n",
       " \"oh no! Well, let's focus on you and your English, shall we?\",\n",
       " 'great! you both are able to support each other by speaking 2 languages and understanding each other culture.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generations[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "658"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "658"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Sure, it comes with practice! Don't give up. It does take a few tries to get comfortable with the poses and breathing techniques. Try to do 15 minutes per day. You'll get there with persistence and before you know it, you'll see the benefits!\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_scores = [{\"text\": gen} for gen in generations]\n",
    "generation_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = evaluate.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_bleu1 = []\n",
    "results_bleu4 = []\n",
    "for gen_score, ref in zip(generation_scores, references):\n",
    "    gen = gen_score['text']\n",
    "    if(len(gen) and len(ref)): # to not include empty ones\n",
    "        result1 = {'generated': gen, 'reference': ref}\n",
    "        result4 = {'generated': gen, 'reference': ref}\n",
    "        result1['score'] = bleu.compute(predictions=[gen], references=[ref], max_order=1)\n",
    "        result4['score'] = bleu.compute(predictions=[gen], references=[ref], max_order=4)\n",
    "        \n",
    "        results_bleu1.append(result1)\n",
    "        results_bleu4.append(result4)\n",
    "\n",
    "        gen_score['bleu1'] = result1['score']['bleu']\n",
    "        gen_score['bleu4'] = result4['score']['bleu']\n",
    "    else:\n",
    "        gen_score['bleu1'] = 0\n",
    "        gen_score['bleu4'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Sure, it comes with practice! Don't give up. It does take a few tries to get comfortable with the poses and breathing techniques. Try to do 15 minutes per day. You'll get there with persistence and before you know it, you'll see the benefits!\",\n",
       "  'overlap': 0.0,\n",
       "  'MLU_match': 31.8,\n",
       "  'ngram_score': 0.413582684192269,\n",
       "  'rpt': 0.08346192000000001,\n",
       "  'bleu1': {'bleu': 0.15686274509803924,\n",
       "   'precisions': [0.1568627450980392],\n",
       "   'brevity_penalty': 1.0,\n",
       "   'length_ratio': 1.8888888888888888,\n",
       "   'translation_length': 51,\n",
       "   'reference_length': 27},\n",
       "  'bleu4': {'bleu': 0.0,\n",
       "   'precisions': [0.1568627450980392, 0.0, 0.0, 0.0],\n",
       "   'brevity_penalty': 1.0,\n",
       "   'length_ratio': 1.8888888888888888,\n",
       "   'translation_length': 51,\n",
       "   'reference_length': 27}},\n",
       " {'text': 'Great! Yoga practice has a lot of benefits. How about your listening and speaking skills? Would you like to practice these using a native English speaker?',\n",
       "  'overlap': 0.047619047619047616,\n",
       "  'MLU_match': 11.8,\n",
       "  'ngram_score': -0.23984571315131742,\n",
       "  'rpt': 0.1160505,\n",
       "  'bleu1': {'bleu': 0.10000000000000002,\n",
       "   'precisions': [0.1],\n",
       "   'brevity_penalty': 1.0,\n",
       "   'length_ratio': 1.875,\n",
       "   'translation_length': 30,\n",
       "   'reference_length': 16},\n",
       "  'bleu4': {'bleu': 0.0,\n",
       "   'precisions': [0.1, 0.0, 0.0, 0.0],\n",
       "   'brevity_penalty': 1.0,\n",
       "   'length_ratio': 1.875,\n",
       "   'translation_length': 30,\n",
       "   'reference_length': 16}},\n",
       " {'text': 'Yes, practice is another helpful practice to build up your English skills.',\n",
       "  'overlap': 0.125,\n",
       "  'MLU_match': 0.8000000000000007,\n",
       "  'ngram_score': -0.008942568029654659,\n",
       "  'rpt': 0.08435975000000001,\n",
       "  'bleu1': {'bleu': 0.05255420588163462,\n",
       "   'precisions': [0.14285714285714285],\n",
       "   'brevity_penalty': 0.36787944117144233,\n",
       "   'length_ratio': 0.5,\n",
       "   'translation_length': 14,\n",
       "   'reference_length': 28},\n",
       "  'bleu4': {'bleu': 0.0,\n",
       "   'precisions': [0.14285714285714285, 0.0, 0.0, 0.0],\n",
       "   'brevity_penalty': 0.36787944117144233,\n",
       "   'length_ratio': 0.5,\n",
       "   'translation_length': 14,\n",
       "   'reference_length': 28}},\n",
       " {'text': \"Oh, you might enjoy this video, but don't try the poses at home, especially not with those IKEA chairs!).\",\n",
       "  'overlap': 0.0625,\n",
       "  'MLU_match': 10.2,\n",
       "  'ngram_score': -0.3470567451400328,\n",
       "  'rpt': 0.09020999999999998,\n",
       "  'bleu1': {'bleu': 0.1476986154218617,\n",
       "   'precisions': [0.16],\n",
       "   'brevity_penalty': 0.9231163463866358,\n",
       "   'length_ratio': 0.9259259259259259,\n",
       "   'translation_length': 25,\n",
       "   'reference_length': 27},\n",
       "  'bleu4': {'bleu': 0.0,\n",
       "   'precisions': [0.16, 0.0, 0.0, 0.0],\n",
       "   'brevity_penalty': 0.9231163463866358,\n",
       "   'length_ratio': 0.9259259259259259,\n",
       "   'translation_length': 25,\n",
       "   'reference_length': 27}},\n",
       " {'text': \"Correct! You got it! 'Have been married' means they were married in the past and are not married now. 'Were married' is the same meaning. Great job! You're learning fast. Keep it up!\",\n",
       "  'overlap': 0.09090909090909091,\n",
       "  'MLU_match': 25.2,\n",
       "  'ngram_score': 0.8471944588862244,\n",
       "  'rpt': 0.11968914,\n",
       "  'bleu1': {'bleu': 0.225,\n",
       "   'precisions': [0.225],\n",
       "   'brevity_penalty': 1.0,\n",
       "   'length_ratio': 1.1764705882352942,\n",
       "   'translation_length': 40,\n",
       "   'reference_length': 34},\n",
       "  'bleu4': {'bleu': 0.0,\n",
       "   'precisions': [0.225, 0.0, 0.0, 0.0],\n",
       "   'brevity_penalty': 1.0,\n",
       "   'length_ratio': 1.1764705882352942,\n",
       "   'translation_length': 40,\n",
       "   'reference_length': 34}}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_scores[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_bleu1 = sorted(results_bleu1, key=lambda item: item['score']['bleu'] if item['score'] else '', reverse=True)\n",
    "results_bleu4 = sorted(results_bleu4, key=lambda item: item['score']['bleu'] if item['score'] else '', reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7165313105737893,\n",
       " 0.38095238095238093,\n",
       " 0.37735849056603776,\n",
       " 0.375,\n",
       " 0.3563218390804598,\n",
       " 0.35416129051928236,\n",
       " 0.3448275862068966,\n",
       " 0.3431521454126054,\n",
       " 0.32786885245901637,\n",
       " 0.32449307785569]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x['score']['bleu'] for x in results_bleu1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.27178805978554255,\n",
       " 0.18709539406264028,\n",
       " 0.1264203703898735,\n",
       " 0.11143093225027423,\n",
       " 0.10026964123698473,\n",
       " 0.08971721455931114,\n",
       " 0.08263765971401953,\n",
       " 0.0810371533925042,\n",
       " 0.07520294647008956,\n",
       " 0.07369081146140266]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x['score']['bleu'] for x in results_bleu4][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertscore = evaluate.load('bertscore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_res = bertscore.compute(predictions=generations, references=references, lang=\"en\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bert_full_res = [{'bert_f1': res, 'generated': gen, 'reference': ref} for res, gen, ref in zip(bert_res['f1'], generations, references)]\n",
    "for i, res in enumerate(bert_full_res):\n",
    "    generation_scores[i]['bertscore_f1'] = res['bert_f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_sorted = sorted(bert_full_res, key=lambda item: item['bert_f1'], reverse=True)\n",
    "bert_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student002_MLU_AoA.png} \n",
      "    \\caption{figs/student/student002 MLU AoA} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student002_TTR_utterances_words_scaffolding_proportion.png} \n",
      "    \\caption{figs/student/student002 TTR utterances words scaffolding proportion} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student002_WF.png} \n",
      "    \\caption{figs/student/student002 WF} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student003_MLU_AoA.png} \n",
      "    \\caption{figs/student/student003 MLU AoA} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student003_TTR_utterances_words_scaffolding_proportion.png} \n",
      "    \\caption{figs/student/student003 TTR utterances words scaffolding proportion} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student003_WF.png} \n",
      "    \\caption{figs/student/student003 WF} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student004_MLU_AoA.png} \n",
      "    \\caption{figs/student/student004 MLU AoA} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student004_TTR_utterances_words_scaffolding_proportion.png} \n",
      "    \\caption{figs/student/student004 TTR utterances words scaffolding proportion} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student004_WF.png} \n",
      "    \\caption{figs/student/student004 WF} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student005_MLU_AoA.png} \n",
      "    \\caption{figs/student/student005 MLU AoA} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student005_TTR_utterances_words_scaffolding_proportion.png} \n",
      "    \\caption{figs/student/student005 TTR utterances words scaffolding proportion} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student005_WF.png} \n",
      "    \\caption{figs/student/student005 WF} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student006_MLU_AoA.png} \n",
      "    \\caption{figs/student/student006 MLU AoA} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student006_TTR_utterances_words_scaffolding_proportion.png} \n",
      "    \\caption{figs/student/student006 TTR utterances words scaffolding proportion} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student006_WF.png} \n",
      "    \\caption{figs/student/student006 WF} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student007_MLU_AoA.png} \n",
      "    \\caption{figs/student/student007 MLU AoA} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student007_TTR_utterances_words_scaffolding_proportion.png} \n",
      "    \\caption{figs/student/student007 TTR utterances words scaffolding proportion} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student007_WF.png} \n",
      "    \\caption{figs/student/student007 WF} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student009_MLU_AoA.png} \n",
      "    \\caption{figs/student/student009 MLU AoA} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student009_TTR_utterances_words_scaffolding_proportion.png} \n",
      "    \\caption{figs/student/student009 TTR utterances words scaffolding proportion} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student009_WF.png} \n",
      "    \\caption{figs/student/student009 WF} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student010_MLU_AoA.png} \n",
      "    \\caption{figs/student/student010 MLU AoA} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student010_TTR_utterances_words_scaffolding_proportion.png} \n",
      "    \\caption{figs/student/student010 TTR utterances words scaffolding proportion} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student010_WF.png} \n",
      "    \\caption{figs/student/student010 WF} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student011_MLU_AoA.png} \n",
      "    \\caption{figs/student/student011 MLU AoA} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student011_TTR_utterances_words_scaffolding_proportion.png} \n",
      "    \\caption{figs/student/student011 TTR utterances words scaffolding proportion} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student011_WF.png} \n",
      "    \\caption{figs/student/student011 WF} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student012_MLU_AoA.png} \n",
      "    \\caption{figs/student/student012 MLU AoA} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student012_TTR_utterances_words_scaffolding_proportion.png} \n",
      "    \\caption{figs/student/student012 TTR utterances words scaffolding proportion} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student012_WF.png} \n",
      "    \\caption{figs/student/student012 WF} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student014_MLU_AoA.png} \n",
      "    \\caption{figs/student/student014 MLU AoA} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student014_TTR_utterances_words_scaffolding_proportion.png} \n",
      "    \\caption{figs/student/student014 TTR utterances words scaffolding proportion} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student014_WF.png} \n",
      "    \\caption{figs/student/student014 WF} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student015_MLU_AoA.png} \n",
      "    \\caption{figs/student/student015 MLU AoA} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student015_TTR_utterances_words_scaffolding_proportion.png} \n",
      "    \\caption{figs/student/student015 TTR utterances words scaffolding proportion} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student015_WF.png} \n",
      "    \\caption{figs/student/student015 WF} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \n",
      "B1: 35\n",
      "B2: 144\n",
      "C1: 29\n",
      "C2: 52\n",
      "$: dollar\n",
      "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
      "'': closing quotation mark\n",
      "    ' ''\n",
      "(: opening parenthesis\n",
      "    ( [ {\n",
      "): closing parenthesis\n",
      "    ) ] }\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ! ?\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "CD: numeral, cardinal\n",
      "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
      "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
      "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "EX: existential there\n",
      "    there\n",
      "FW: foreign word\n",
      "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
      "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
      "    terram fiche oui corporis ...\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "JJR: adjective, comparative\n",
      "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
      "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
      "    cozier creamier crunchier cuter ...\n",
      "JJS: adjective, superlative\n",
      "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
      "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
      "    dearest deepest densest dinkiest ...\n",
      "LS: list item marker\n",
      "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
      "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
      "    two\n",
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "PDT: pre-determiner\n",
      "    all both half many quite such sure this\n",
      "POS: genitive marker\n",
      "    ' 's\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "RBR: adverb, comparative\n",
      "    further gloomier grander graver greater grimmer harder harsher\n",
      "    healthier heavier higher however larger later leaner lengthier less-\n",
      "    perfectly lesser lonelier longer louder lower more ...\n",
      "RBS: adverb, superlative\n",
      "    best biggest bluntest earliest farthest first furthest hardest\n",
      "    heartiest highest largest least less most nearest second tightest worst\n",
      "RP: particle\n",
      "    aboard about across along apart around aside at away back before behind\n",
      "    by crop down ever fast for forth from go high i.e. in into just later\n",
      "    low more off on open out over per pie raising start teeth that through\n",
      "    under unto up up-pp upon whole with you\n",
      "SYM: symbol\n",
      "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "UH: interjection\n",
      "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
      "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
      "    man baby diddle hush sonuvabitch ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "WDT: WH-determiner\n",
      "    that what whatever which whichever\n",
      "WP: WH-pronoun\n",
      "    that what whatever whatsoever which who whom whosoever\n",
      "WP$: WH-pronoun, possessive\n",
      "    whose\n",
      "WRB: Wh-adverb\n",
      "    how however whence whenever where whereby whereever wherein whereof why\n",
      "``: opening quotation mark\n",
      "    ` ``\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kuba\\AppData\\Local\\Temp\\ipykernel_23952\\305697343.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  previous_utts = pd.concat(\n",
      "C:\\Users\\kuba\\AppData\\Local\\Temp\\ipykernel_23952\\305697343.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  previous_utts = pd.concat(\n",
      "C:\\Users\\kuba\\AppData\\Local\\Temp\\ipykernel_23952\\3500320797.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  previous_utts = pd.concat(\n",
      "C:\\Users\\kuba\\AppData\\Local\\Temp\\ipykernel_23952\\3500320797.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  previous_utts = pd.concat(\n",
      "C:\\Users\\kuba\\AppData\\Local\\Temp\\ipykernel_23952\\305697343.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  previous_utts = pd.concat(\n",
      "C:\\Users\\kuba\\AppData\\Local\\Temp\\ipykernel_23952\\3500320797.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  previous_utts = pd.concat(\n"
     ]
    }
   ],
   "source": [
    "%run func_declarations.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VO of generated utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (generation, context) in zip(generation_scores, contexts):\n",
    "    tokens = tokenize_and_preprocess(generation['text'], True)\n",
    "    previous_tokens = tokenize_and_preprocess(context.split(\"<|endoftext|>\")[-2], True)\n",
    "\n",
    "    intersect = set(previous_tokens).intersection(set(tokens))\n",
    "    union = set(previous_tokens).union(set(tokens))\n",
    "    \n",
    "    generation[\"overlap\"] = len(intersect)/len(union) if union else 0 # jaccard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['So I know her because of Ihor. And now she does online sessions.',\n",
       " 'ah, brilliant!',\n",
       " \"Sometimes it's yoga, sometimes it's pilates. And I decide to join. Two times per week. I like it.\",\n",
       " 'I started doing yoga in Kyiv back in 2014. It was not an easy year as you remember and I really appreciated the relaxing effects of yoga. And I have been practicing ever since!',\n",
       " 'And even bought a fitness mat, ball and top for sessions ).',\n",
       " 'Do you practice at home?',\n",
       " 'Do you practice yourself now? Yes, I practice at home usually. One time at the office )).',\n",
       " 'I do, yes, I follow a couple of yoga youtube channels and do the sessions from there.',\n",
       " 'Is it hard? Because I thought about more yoga or pilates.',\n",
       " '']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts[0].split(\"<|endoftext|>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complexity match MLU of generated utterances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (generation, context) in zip(generation_scores, contexts):\n",
    "    tokens = tokenize_and_preprocess(generation['text'], False)\n",
    "    student_tokens = [tokenize_and_preprocess(c, False) for c in context.split(\"<|endoftext|>\")[::2]]\n",
    "\n",
    "    MLU_gen = len(tokens)\n",
    "    MLU_student = np.mean([len(utt) for utt in student_tokens])\n",
    "\n",
    "    generation['MLU_match'] = MLU_gen-MLU_student\n",
    "\n",
    "    # intersect = set(previous_tokens).intersection(set(tokens))\n",
    "    # union = set(previous_tokens).union(set(tokens))\n",
    "    \n",
    "    # generation[\"overlap\"] = len(intersect)/len(union) if union else 0 # jaccard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Sure, it comes with practice! Don't give up. It does take a few tries to get comfortable with the poses and breathing techniques. Try to do 15 minutes per day. You'll get there with persistence and before you know it, you'll see the benefits!\",\n",
       "  'overlap': 0.0,\n",
       "  'MLU_match': 31.8},\n",
       " {'text': 'Great! Yoga practice has a lot of benefits. How about your listening and speaking skills? Would you like to practice these using a native English speaker?',\n",
       "  'overlap': 0.047619047619047616,\n",
       "  'MLU_match': 11.8},\n",
       " {'text': 'Yes, practice is another helpful practice to build up your English skills.',\n",
       "  'overlap': 0.125,\n",
       "  'MLU_match': 0.8000000000000007},\n",
       " {'text': \"Oh, you might enjoy this video, but don't try the poses at home, especially not with those IKEA chairs!).\",\n",
       "  'overlap': 0.0625,\n",
       "  'MLU_match': 10.2},\n",
       " {'text': \"Correct! You got it! 'Have been married' means they were married in the past and are not married now. 'Were married' is the same meaning. Great job! You're learning fast. Keep it up!\",\n",
       "  'overlap': 0.09090909090909091,\n",
       "  'MLU_match': 25.2},\n",
       " {'text': \"Yes, you're warming up! Remember, we can use present perfect for a past action that has an effect on the present.\",\n",
       "  'overlap': 0.0,\n",
       "  'MLU_match': 13.0},\n",
       " {'text': 'No. They were once a celebrated couple!',\n",
       "  'overlap': 0.3333333333333333,\n",
       "  'MLU_match': 2.8},\n",
       " {'text': '* propose * introduce * pass * comes into effect * is passed * is introduced',\n",
       "  'overlap': 0.0,\n",
       "  'MLU_match': -3.4000000000000004},\n",
       " {'text': \"...and if the bill gets approved by the Parliament, then it becomes an Act. It's like a law that people have to follow.\",\n",
       "  'overlap': 0.0,\n",
       "  'MLU_match': 11.4},\n",
       " {'text': \"That's right! In UK parliamentary jargon, when a proposal is successful in the House of Commons, it 'passes'. In the US, a passed proposal is called a law - so the British would say the bill 'passed', while for Americans, the bill 'becomes a law'.\",\n",
       "  'overlap': 0.0,\n",
       "  'MLU_match': 35.8}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_coeff = json.load(open(\"ngrams_scaff.txt\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.7496312271859153, 'the snow'],\n",
       " [1.1564406480866836, 'is called'],\n",
       " [0.5455720135187181, 'the meaning'],\n",
       " [0.5268666293446779, 'the people'],\n",
       " [0.5088000832813544, 'that is']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_coeff[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_texts = [ngram[1] for ngram in ngrams_coeff]\n",
    "ngram_coeffs = [ngram[0] for ngram in ngrams_coeff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for generation in generation_scores:\n",
    "    tokens = tokenize_and_preprocess(generation['text'], False)\n",
    "    bigrams = nltk.ngrams(tokens, 2)\n",
    "    trigrams = nltk.ngrams(tokens, 3)\n",
    "    ngram_list = (list(bigrams) + list(trigrams))\n",
    "    ngram_score = 0\n",
    "    for ngram in ngram_list:\n",
    "        if ' '.join(ngram) in ngram_texts:\n",
    "            # print(ngram, ngram_texts.index(' '.join(ngram)), ngram_coeffs[ngram_texts.index(' '.join(ngram))])\n",
    "            ngram_score += ngram_coeffs[ngram_texts.index(' '.join(ngram))]\n",
    "    generation['ngram_score'] = ngram_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Sure, it comes with practice! Don't give up. It does take a few tries to get comfortable with the poses and breathing techniques. Try to do 15 minutes per day. You'll get there with persistence and before you know it, you'll see the benefits!\",\n",
       "  'overlap': 0.0,\n",
       "  'MLU_match': 31.8,\n",
       "  'ngram_score': 0.413582684192269},\n",
       " {'text': 'Great! Yoga practice has a lot of benefits. How about your listening and speaking skills? Would you like to practice these using a native English speaker?',\n",
       "  'overlap': 0.047619047619047616,\n",
       "  'MLU_match': 11.8,\n",
       "  'ngram_score': -0.23984571315131742},\n",
       " {'text': 'Yes, practice is another helpful practice to build up your English skills.',\n",
       "  'overlap': 0.125,\n",
       "  'MLU_match': 0.8000000000000007,\n",
       "  'ngram_score': -0.008942568029654659},\n",
       " {'text': \"Oh, you might enjoy this video, but don't try the poses at home, especially not with those IKEA chairs!).\",\n",
       "  'overlap': 0.0625,\n",
       "  'MLU_match': 10.2,\n",
       "  'ngram_score': -0.3470567451400328},\n",
       " {'text': \"Correct! You got it! 'Have been married' means they were married in the past and are not married now. 'Were married' is the same meaning. Great job! You're learning fast. Keep it up!\",\n",
       "  'overlap': 0.09090909090909091,\n",
       "  'MLU_match': 25.2,\n",
       "  'ngram_score': 0.8471944588862244}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_scores[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Sure, it comes with practice! Don't give up. It does take a few tries to get comfortable with the poses and breathing techniques. Try to do 15 minutes per day. You'll get there with persistence and before you know it, you'll see the benefits!\",\n",
       "  'overlap': 0.0,\n",
       "  'MLU_match': 31.8,\n",
       "  'ngram_score': 0.413582684192269,\n",
       "  'rpt': 0.08346192000000001,\n",
       "  'bleu1': 0.15686274509803924,\n",
       "  'bleu4': 0.0,\n",
       "  'bertscore_f1': 0.8302353024482727},\n",
       " {'text': 'Great! Yoga practice has a lot of benefits. How about your listening and speaking skills? Would you like to practice these using a native English speaker?',\n",
       "  'overlap': 0.047619047619047616,\n",
       "  'MLU_match': 11.8,\n",
       "  'ngram_score': -0.23984571315131742,\n",
       "  'rpt': 0.1160505,\n",
       "  'bleu1': 0.10000000000000002,\n",
       "  'bleu4': 0.0,\n",
       "  'bertscore_f1': 0.8552031517028809},\n",
       " {'text': 'Yes, practice is another helpful practice to build up your English skills.',\n",
       "  'overlap': 0.125,\n",
       "  'MLU_match': 0.8000000000000007,\n",
       "  'ngram_score': -0.008942568029654659,\n",
       "  'rpt': 0.08435975000000001,\n",
       "  'bleu1': 0.05255420588163462,\n",
       "  'bleu4': 0.0,\n",
       "  'bertscore_f1': 0.8497314453125},\n",
       " {'text': \"Oh, you might enjoy this video, but don't try the poses at home, especially not with those IKEA chairs!).\",\n",
       "  'overlap': 0.0625,\n",
       "  'MLU_match': 10.2,\n",
       "  'ngram_score': -0.3470567451400328,\n",
       "  'rpt': 0.09020999999999998,\n",
       "  'bleu1': 0.1476986154218617,\n",
       "  'bleu4': 0.0,\n",
       "  'bertscore_f1': 0.8324360251426697},\n",
       " {'text': \"Correct! You got it! 'Have been married' means they were married in the past and are not married now. 'Were married' is the same meaning. Great job! You're learning fast. Keep it up!\",\n",
       "  'overlap': 0.09090909090909091,\n",
       "  'MLU_match': 25.2,\n",
       "  'ngram_score': 0.8471944588862244,\n",
       "  'rpt': 0.11968914,\n",
       "  'bleu1': 0.225,\n",
       "  'bleu4': 0.0,\n",
       "  'bertscore_f1': 0.8607983589172363}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_scores[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, gen in enumerate(generation_scores):\n",
    "    gen['reference'] = references[i]\n",
    "    gen['context'] = contexts[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Sure, it comes with practice! Don't give up. It does take a few tries to get comfortable with the poses and breathing techniques. Try to do 15 minutes per day. You'll get there with persistence and before you know it, you'll see the benefits!\",\n",
       "  'overlap': 0.0,\n",
       "  'MLU_match': 31.8,\n",
       "  'ngram_score': 0.413582684192269,\n",
       "  'rpt': 0.08346192000000001,\n",
       "  'bleu1': 0.15686274509803924,\n",
       "  'bleu4': 0.0,\n",
       "  'bertscore_f1': 0.8302353024482727,\n",
       "  'reference': \"Just to note, practice as a verb is an American spelling, the British one is practise. I should have used 'practise', sorry!\",\n",
       "  'context': \"So I know her because of Ihor. And now she does online sessions.<|endoftext|>ah, brilliant!<|endoftext|>Sometimes it's yoga, sometimes it's pilates. And I decide to join. Two times per week. I like it.<|endoftext|>I started doing yoga in Kyiv back in 2014. It was not an easy year as you remember and I really appreciated the relaxing effects of yoga. And I have been practicing ever since!<|endoftext|>And even bought a fitness mat, ball and top for sessions ).<|endoftext|>Do you practice at home?<|endoftext|>Do you practice yourself now? Yes, I practice at home usually. One time at the office )).<|endoftext|>I do, yes, I follow a couple of yoga youtube channels and do the sessions from there.<|endoftext|>Is it hard? Because I thought about more yoga or pilates.<|endoftext|>\"},\n",
       " {'text': 'Great! Yoga practice has a lot of benefits. How about your listening and speaking skills? Would you like to practice these using a native English speaker?',\n",
       "  'overlap': 0.047619047619047616,\n",
       "  'MLU_match': 11.8,\n",
       "  'ngram_score': -0.23984571315131742,\n",
       "  'rpt': 0.1160505,\n",
       "  'bleu1': 0.10000000000000002,\n",
       "  'bleu4': 0.0,\n",
       "  'bertscore_f1': 0.8552031517028809,\n",
       "  'reference': \"And the noun is practice. as in 'regular yoga practice is wonderful for you'.\",\n",
       "  'context': \"Sometimes it's yoga, sometimes it's pilates. And I decide to join. Two times per week. I like it.<|endoftext|>I started doing yoga in Kyiv back in 2014. It was not an easy year as you remember and I really appreciated the relaxing effects of yoga. And I have been practicing ever since!<|endoftext|>And even bought a fitness mat, ball and top for sessions ).<|endoftext|>Do you practice at home?<|endoftext|>Do you practice yourself now? Yes, I practice at home usually. One time at the office )).<|endoftext|>I do, yes, I follow a couple of yoga youtube channels and do the sessions from there.<|endoftext|>Is it hard? Because I thought about more yoga or pilates.<|endoftext|>Just to note, practice as a verb is an American spelling, the British one is practise. I should have used 'practise', sorry!<|endoftext|>For example, two times with this girl <YOGA INSTRUCTOR> and one time myself.<|endoftext|>\"}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_scores[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"oh, see if you can infer the meaning from the context clues! 'the meaning is like 'ignore'/ 'fail to notice/recognize' - does that help?\",\n",
       "  'overlap': 0.07142857142857142,\n",
       "  'MLU_match': 19.4,\n",
       "  'ngram_score': 3.0327525160457287,\n",
       "  'rpt': 0.060701780000000004,\n",
       "  'bleu1': 0.13333333333333333,\n",
       "  'bleu4': 0.0,\n",
       "  'bertscore_f1': 0.8421195149421692,\n",
       "  'reference': \"oversee = supervise and overgrown makes no sense here so...'overlook' is the one you want!\",\n",
       "  'context': \"what they are like.<|endoftext|>good correction! a hell of a lot actually. <STUDENT> would you like to have a quick go at e.g. page 147 from your book before we finish!? <STUDENT> (sorry).<|endoftext|>Sure.<|endoftext|>ok...<|endoftext|>1d.<|endoftext|>yes.<|endoftext|>no idea about number 2 but I would say A.<|endoftext|>so the meaning is like 'ignore'/ 'fail to notice/recognise' - does that help?<|endoftext|>I don't know the meaning of the words.<|endoftext|>\"},\n",
       " {'text': \"That's right! In UK parliamentary jargon, when a proposal is successful in the House of Commons, it 'passes'. In the US, a passed proposal is called a law - so the British would say the bill 'passed', while for Americans, the bill 'becomes a law'.\",\n",
       "  'overlap': 0.0,\n",
       "  'MLU_match': 35.8,\n",
       "  'ngram_score': 1.9521714031756576,\n",
       "  'rpt': 0.12812968000000002,\n",
       "  'bleu1': 0.24528301886792456,\n",
       "  'bleu4': 0.0,\n",
       "  'bertscore_f1': 0.8641527891159058,\n",
       "  'reference': \"And if it's passed, the bill becomes a law. and the govenment introduces a new law. Does it work in a similar way in Ukraine?\",\n",
       "  'context': \"to introduce a law - can I have something like description? Ah, a proposal, I see. An when it works? Which verb is right?<|endoftext|>Yes, sure, if the govenment introduces a new law, the law is active now. I'm not sure whether it is a law or just a proposal at this stage! But I remember reading about it on the news.<|endoftext|>Ok! I see. I mean in general. Which verbs work with a law in different stages?<|endoftext|>Ok, let's see. A proposed law that will be debated in Parliament is called a bill.<|endoftext|>I see.<|endoftext|>Someone (a member of Parliament, or MP) proposes a bill. Then the Parliament votes on it. The bill either passes or doesn't pass. Or sometimes it passes the House of Commons but not the House of Lords like the Brexit bill.<|endoftext|>I se. thank you.<|endoftext|>It's the same in the US, a bill is proposed to Congress.<|endoftext|>*see.<|endoftext|>\"},\n",
       " {'text': \"That's right! to look the other way, to snub or ignore. in formal English, 'to give the cold shoulder' is often used to talk about a group or an organization which refuses to consider or discuss something, like when a government ignores the claims of activists. Does that help clarify?\",\n",
       "  'overlap': 0.02857142857142857,\n",
       "  'MLU_match': 20.6,\n",
       "  'ngram_score': 1.9110933553832232,\n",
       "  'rpt': 0.15035020000000002,\n",
       "  'bleu1': 0.10526315789473682,\n",
       "  'bleu4': 0.0,\n",
       "  'bertscore_f1': 0.8493436574935913,\n",
       "  'reference': \"a good colloquial word for 'give a silent treatment' is to sulk, you probably know this one.\",\n",
       "  'context': \"a shoulder to cry on' means someone you can rely on in difficult moments (who will listen and, if necessary, give you 'a shoulder to cry on' if you need).<|endoftext|>Exactly!<|endoftext|>In Italian we don't have it! Even though it is very clear, yes. I believe that 'rub shoulders' means to have an argument or, at least, some sort of disagreement...is that the case?<|endoftext|>No, actually, it means to meet some people from time to time, especially used to show status. She says she frequently rubs shoulders with celebrities.<|endoftext|>Really? Wow, I really didn't know that. and I was 'sort of sure'...okay, let me try with the last one I believe I know:.<|endoftext|>Yes, it's a good one! Now, to make it more confusing, in American English it's 'rub elbows'.<|endoftext|>to give the cold sholder' means to ignore or avoid answering to someone, right? As in a couple, I guess... where one of the two gives the 'silent treatment' to the other. is that right?<|endoftext|>Hmm, it definitely means to snub someone, dismiss and ignore when you see them. but I wouldn't say it's an equivalent to the silent treatment.<|endoftext|>Okay...I don't know why when reading it I figured a couple in that situation...but okay, so in general it means to snub someone.<|endoftext|>\"},\n",
       " {'text': 'Oh right! Corpus is a bit like a giant website with many words and examples organized in different ways. You click the word you are investigating and it brings up a list of examples! But the specific thing you want -the collocates part- is the most useful for your English learning! You will see a list of words which are regularly used by native speakers after the word you looked up - words that go well together!',\n",
       "  'overlap': 0.11627906976744186,\n",
       "  'MLU_match': 62.4,\n",
       "  'ngram_score': 1.5805707706962246,\n",
       "  'rpt': 0.06140594999999999,\n",
       "  'bleu1': 0.10975609756097561,\n",
       "  'bleu4': 0.0,\n",
       "  'bertscore_f1': 0.8367946147918701,\n",
       "  'reference': \"Ah i see. OK so if you just out in 'list' then in just gives you the one word that you enter in any context.\",\n",
       "  'context': \"Okk I see the correction, thank you!<|endoftext|>ok! You know one really odd thing that's survived the UK? Religious assemblies in school! Bizzare given the vast majority of parents never go to church or whatever - just a hangover from the past. You know that use of hangover right?<|endoftext|>Sure, we had them in the school I worked. No I didn't! I like it (hangover use).<|endoftext|>yes i guessed it might be new! Just had a look on the corpus and there are several examples mixed in with the more frequent normal meaning.<|endoftext|>OK, I'll have a look.<|endoftext|>Three examples: There is something of a hangover from the last election at the moment. / This rule seems to be a hangover from the time when …/ Being strong and silent um is a kind of is a kind of nineteenth century hangover …. examples 2 and 3 a bit clearer i guess.<|endoftext|>Please, help me to understand the Corpus thingy...<|endoftext|>Ok...in what way? You mean the site? Or what it is? Or the specific examples?<|endoftext|>I get on the website, I write the word and then I have to click on something but there are a lot of options... List Chart Collocates Compare KWIC.<|endoftext|>\"},\n",
       " {'text': \"Great - that's absolutely fine! We sometimes use just 'river' in English for this kind of sentence - you remember the word choice lesson we had on Monday don't you! So, next time, you could just say something like 'Thames is a famous river in London'. Nice work!\",\n",
       "  'overlap': 0.16,\n",
       "  'MLU_match': 44.0,\n",
       "  'ngram_score': 1.5619104367297683,\n",
       "  'rpt': 0.036309690000000006,\n",
       "  'bleu1': 0.21021321531261453,\n",
       "  'bleu4': 0.0,\n",
       "  'bertscore_f1': 0.8482754826545715,\n",
       "  'reference': \"Hold on...my example was confusing I;m sorry - look at this one: 'The Yangtze River is in China.' Can you add a diffrent word! Sorry go ahead: for example: '_______ River Thames is in London.' ?\",\n",
       "  'context': \"ok,,thanks.<|endoftext|>We can caome back to your sentences later maybe - the important thing is that you have understood the past simple/continuous rule - well done.<|endoftext|>yes, thanks a lot.<|endoftext|>But the use of articles (the/a) is a grammar point that you should improve too - it will help your score...here we go....hold on!<|endoftext|>ok.<|endoftext|>So <STUDENT> can you give me sentence from the following keywords please?! : Thames/London ? (You know what this is right?) For example is I gave you these keywords : Heathrow/London you could say: Heathrow is an airport in London. ... OK? So..Thames/London...give me a sentence if oyu can.<|endoftext|>Thames is a river in London. .<|endoftext|>OK thanks - I'll give you one back! 'The Yangtze is the longest river in China. Can you add a word in your example??'. Just one little word!<|endoftext|>Thames is a famous river in London.<|endoftext|>\"},\n",
       " {'text': 'Correct! When the weather is frosty( conditional), the snow falls ( present simple).',\n",
       "  'overlap': 0.375,\n",
       "  'MLU_match': -3.0,\n",
       "  'ngram_score': 1.558416113253867,\n",
       "  'rpt': 0.1145596,\n",
       "  'bleu1': 0.13483257878266341,\n",
       "  'bleu4': 0.0,\n",
       "  'bertscore_f1': 0.8293316960334778,\n",
       "  'reference': \"Yes, that's right! Generally, you won't have a future form with 'will' after if / when / unless.\",\n",
       "  'context': \"But I didn't take it. I thought wouldn't have snow this winter ). sorry. sanki').<|endoftext|>Aaa, ok, it's a sledge. Oh, that would have been fun! If you had the sledge.<|endoftext|>ok! Thanks. So now I'm thinking how can I pick it up fast from them ).<|endoftext|>Are they still in Troyeshchina?<|endoftext|>I think if the weather will be frosty we will have the snow three or four days. I'm not sure about conditionals ). Yes, They are still there.<|endoftext|>Do you think it's real / unreal, past / present / future?<|endoftext|>real and future.<|endoftext|>Absolutely. If + present simple, will + verb.<|endoftext|>so. If the weather is frosty We will have the snow. we.<|endoftext|>\"},\n",
       " {'text': \"That's correct! 'Political' is an adjective, so we need a noun to describe. Great effort!\",\n",
       "  'overlap': 0.1,\n",
       "  'MLU_match': 10.6,\n",
       "  'ngram_score': 1.4907962041930047,\n",
       "  'rpt': 0.08502717,\n",
       "  'bleu1': 0.071697430079132,\n",
       "  'bleu4': 0.0,\n",
       "  'bertscore_f1': 0.8352817296981812,\n",
       "  'reference': \"Yes sorry <STUDENT> just to be clear - you know the word policy means 'plan' right? But a specific plan (that a government of company/organisation has).\",\n",
       "  'context': \"yes..maybe it is the capital of one country.<|endoftext|>OK well...'political' is the adjective...so financial and political centre is grammatically correct anyway.<|endoftext|>I don't know the word of noun.<|endoftext|>One more: “One of the best ____ “(singular or plural noun next)?<|endoftext|>plural.<|endoftext|>Sorry you mean you didn't know the word policy was a noun?<|endoftext|>ways.<|endoftext|>Yes good!<|endoftext|>yes.. but I studied just now is political.<|endoftext|>\"},\n",
       " {'text': \"Absolutely! That's a great idea. You'll be able to have a go at writing a formal letter, and you'll use all the phrases we've talked about. Do you know how to write a formal letter? Here's a checklist. Does that sound good?\",\n",
       "  'overlap': 0.09523809523809523,\n",
       "  'MLU_match': 29.4,\n",
       "  'ngram_score': 1.477359627423054,\n",
       "  'rpt': 0.06443046,\n",
       "  'bleu1': 0.14285714285714285,\n",
       "  'bleu4': 0.0,\n",
       "  'bertscore_f1': 0.8360509872436523,\n",
       "  'reference': \"And if they cancelled on time, 'Your refund will be issued within 5 working days' or something like that. Good idea! Yes :).\",\n",
       "  'context': \"We are sorry to hear you will miss your class?<|endoftext|>Hi <STUDENT>, I'm very sorry, I need to cancel tomorrow's class because I'm going on a business trip. What's the best way to do it? Yes, good one!<|endoftext|>I'm very sorry to hear you can't do your class tomorrow. As stated in our terms and conditions, refunds are not issued for cancellations that took place after 7 pm the day before the class. And then should I add something? Like you will be charged for the lesson?<|endoftext|>Please make sure you inform us about a cancellation in advance next time to avoid this problem in the future. Well, I think it's clear you're not giving them their money back. Also, teachers give classes and students have classes. or attend classes.<|endoftext|>Ok so nothing about charge? ).<|endoftext|>attend is a more formal word, so probably good for a formal letter. What would you like to add?<|endoftext|>Ok. I mean you will be charged for the lesson.<|endoftext|>Yes, or something like, 'You cancelled at 8 pm, which means you will be charged for the lesson.<|endoftext|>Ok! I see. Maybe I can write a letter as my home work?<|endoftext|>\"},\n",
       " {'text': 'Understood? We often use the present simple to talk about routines, and things we do regularly. Does that help clarify it?',\n",
       "  'overlap': 0.0,\n",
       "  'MLU_match': 13.8,\n",
       "  'ngram_score': 1.4583459264119507,\n",
       "  'rpt': 0.05747732999999999,\n",
       "  'bleu1': 0.16087681104855342,\n",
       "  'bleu4': 0.0,\n",
       "  'bertscore_f1': 0.8470606803894043,\n",
       "  'reference': \"Do you remember 'unless'? unless = if not. If he doesn't make dinner, I will have to do it. Unless he makes dinner, I will have to do it.\",\n",
       "  'context': \"real and future.<|endoftext|>Absolutely. If + present simple, will + verb.<|endoftext|>so. If the weather is frosty We will have the snow. we.<|endoftext|>Yes, that's right! Generally, you won't have a future form with 'will' after if / when / unless.<|endoftext|>Ah! Ok!<|endoftext|>When I come home, I will watch a movie. (joking, no one is away from home anymore!).<|endoftext|>haha.<|endoftext|>Unless he makes dinner, I will have to do it. Well, that's not true, lots of people work away from home. just not us.<|endoftext|>yes! Unless he makes dinner, I will have to do it. I'm not sure about the meaning.<|endoftext|>\"},\n",
       " {'text': \"good choice of word! so the sentence becomes: 30% of turists were satisfied with their experience. the phrase 'were satisfied' is a good example of a phrasal phrase. notice how we use 'were' instead of 'was' because we're talking about more than one person? and the word'satisfied' is an adjective - a word that describes nouns - and we like to use adjectives after links words like 'were' to make sentences more interesting. can you think of another adjective we can use to describe the turists experience?\",\n",
       "  'overlap': 0.034482758620689655,\n",
       "  'MLU_match': 84.0,\n",
       "  'ngram_score': 1.284790957289876,\n",
       "  'rpt': 0.06604403,\n",
       "  'bleu1': 0.1368421052631579,\n",
       "  'bleu4': 0.0,\n",
       "  'bertscore_f1': 0.8060790300369263,\n",
       "  'reference': 'ah! not a bad idea ....but a bit of a jump because I guess for example the _________ might just live next door you know?! visitors!!',\n",
       "  'context': \"From the museum?<|endoftext|>or: 'their._________? instead of 'the museum' I mean.<|endoftext|>From their services?<|endoftext|>OK so bringing these two things together...e.g. '30% of people were satisified with their visit' = good. satisfied.<|endoftext|>Ok understood.<|endoftext|>ok great so..using that example sentence as a model can you replace the word 'visit' with a different word? exp....'?!<|endoftext|>Experience?<|endoftext|>yes good! that's a good option in this context. and can you replace 'people' ? Who are the peopel in this context? not a trick question - the answer is in the words in the charts.<|endoftext|>Turists.<|endoftext|>\"}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_sorted_by_ngram = sorted(generation_scores, key=lambda x: x['ngram_score'], reverse=True)\n",
    "scores_sorted_by_ngram[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_scores = [{'text': ref} for ref in references]\n",
    "for ref_score, context in zip(reference_scores, contexts):\n",
    "    ref = ref_score['text']\n",
    "    \n",
    "    tokens_vo = tokenize_and_preprocess(ref, True)\n",
    "    previous_tokens_vo = tokenize_and_preprocess(context.split(\"<|endoftext|>\")[-2], True)\n",
    "\n",
    "    intersect = set(previous_tokens_vo).intersection(set(tokens_vo))\n",
    "    union = set(previous_tokens_vo).union(set(tokens_vo))\n",
    "    \n",
    "    ref_score['overlap'] = len(intersect)/len(union) if union else 0 # jaccard\n",
    "\n",
    "    tokens = tokenize_and_preprocess(ref, False)\n",
    "    student_tokens = [tokenize_and_preprocess(c, False) for c in context.split(\"<|endoftext|>\")[::2]]\n",
    "\n",
    "    MLU_gen = len(tokens)\n",
    "    MLU_student = np.mean([len(utt) for utt in student_tokens])\n",
    "\n",
    "    ref_score['MLU_match'] = MLU_gen-MLU_student\n",
    "\n",
    "    bigrams = nltk.ngrams(tokens, 2)\n",
    "    trigrams = nltk.ngrams(tokens, 3)\n",
    "    ngram_list = (list(bigrams) + list(trigrams))\n",
    "    ngram_score = 0\n",
    "    for ngram in ngram_list:\n",
    "        if ' '.join(ngram) in ngram_texts:\n",
    "            # print(ngram, ngram_texts.index(' '.join(ngram)), ngram_coeffs[ngram_texts.index(' '.join(ngram))])\n",
    "            ngram_score += ngram_coeffs[ngram_texts.index(' '.join(ngram))]\n",
    "    ref_score['ngram_score'] = ngram_score\n",
    "\n",
    "    ref_score['bleu1'] = 1  # they ARE the references\n",
    "    ref_score['bleu4'] = 1\n",
    "    ref_score['bertscore_f1'] = 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Just to note, practice as a verb is an American spelling, the British one is practise. I should have used 'practise', sorry!\",\n",
       "  'overlap': 0.0,\n",
       "  'MLU_match': 7.800000000000001,\n",
       "  'ngram_score': 0.46713450189846545,\n",
       "  'bleu1': 1,\n",
       "  'bleu4': 1,\n",
       "  'bertscore_f1': 1},\n",
       " {'text': \"And the noun is practice. as in 'regular yoga practice is wonderful for you'.\",\n",
       "  'overlap': 0.08333333333333333,\n",
       "  'MLU_match': -0.1999999999999993,\n",
       "  'ngram_score': -0.02643475191698528,\n",
       "  'bleu1': 1,\n",
       "  'bleu4': 1,\n",
       "  'bertscore_f1': 1},\n",
       " {'text': 'I like that I can choose easier or harder sessions. It depends whether you want to spell it in a British or American way)).',\n",
       "  'overlap': 0.0,\n",
       "  'MLU_match': 12.8,\n",
       "  'ngram_score': 0.35095014965583327,\n",
       "  'bleu1': 1,\n",
       "  'bleu4': 1,\n",
       "  'bertscore_f1': 1},\n",
       " {'text': 'No! Tell me. Both are good, did you see and did you watch. and Have you seen? would be even better.',\n",
       "  'overlap': 0.15384615384615385,\n",
       "  'MLU_match': 11.2,\n",
       "  'ngram_score': -0.31248915335754,\n",
       "  'bleu1': 1,\n",
       "  'bleu4': 1,\n",
       "  'bertscore_f1': 1}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_scores[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the base prompt now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generations_base = []\n",
    "references_base = []\n",
    "contexts_base = []\n",
    "\n",
    "for filename in ['base_prompt_model_out_1.txt', 'base_prompt_model_out_correct_2.txt', 'base_prompt_model_out_correct_3.txt']:\n",
    "    with open(filename, 'r',  encoding=\"utf8\") as f:\n",
    "        context = \"\"\n",
    "        gen = \"\"\n",
    "        long_scaff = False\n",
    "        for line in f.readlines():\n",
    "            if long_scaff:\n",
    "                if '=====================' in line:\n",
    "                    contexts_base.append(context)\n",
    "                    context = \"\"\n",
    "                    generations_base.append(gen)\n",
    "                    gen = \"\"\n",
    "                    long_scaff = False\n",
    "                else:\n",
    "                    if line.strip():\n",
    "                        gen += ' ' + line.strip() \n",
    "            else:\n",
    "                if line.split()[:2] == ['ORIGINAL', 'SCAFFOLDING:']:\n",
    "                    references_base.append(' '.join(line.split()[2:]))\n",
    "                elif line.split()[:2] == ['GENERATED', 'SCAFFOLDING:']:\n",
    "                    gen += (' '.join(line.split()[2:]))\n",
    "                    long_scaff = True\n",
    "                elif line.split()[:1] == ['STUDENT:'] or line.split()[:1] == ['TEACHER:']:\n",
    "                  context += (' '.join(line.split()[1:]) + \"<|endoftext|>\")\n",
    "                elif '=====================' in line:\n",
    "                  contexts_base.append(context)\n",
    "                  context = \"\"\n",
    "                  generations_base.append(gen)\n",
    "                  gen = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = evaluate.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bertscore = evaluate.load('bertscore')\n",
    "bert_res_base = bertscore.compute(predictions=generations_base, references=references_base, lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "generations_base_scores = [{'text': gen} for gen in generations_base]\n",
    "\n",
    "bert_full_res_base = [{'bert_f1': res, 'generated': gen, 'reference': ref} for res, gen, ref in zip(bert_res_base['f1'], generations_base, references_base)]\n",
    "for i, res in enumerate(bert_full_res_base):\n",
    "    generations_base_scores[i]['bertscore_f1'] = res['bert_f1']\n",
    "\n",
    "# loop for everything else\n",
    "\n",
    "for gen_base_score, ref, context in zip(generations_base_scores, references_base, contexts_base):\n",
    "    gen = gen_base_score['text']\n",
    "    \n",
    "    tokens_vo = tokenize_and_preprocess(gen, True)\n",
    "    previous_tokens_vo = tokenize_and_preprocess(context.split(\"<|endoftext|>\")[-2], True)\n",
    "\n",
    "    intersect = set(previous_tokens_vo).intersection(set(tokens_vo))\n",
    "    union = set(previous_tokens_vo).union(set(tokens_vo))\n",
    "    \n",
    "    gen_base_score['overlap'] = len(intersect)/len(union) if union else 0 # jaccard\n",
    "\n",
    "    tokens = tokenize_and_preprocess(gen, False)\n",
    "    student_tokens = [tokenize_and_preprocess(c, False) for c in context.split(\"<|endoftext|>\")[::2]]\n",
    "\n",
    "    MLU_gen = len(tokens)\n",
    "    MLU_student = np.mean([len(utt) for utt in student_tokens])\n",
    "\n",
    "    gen_base_score['MLU_match'] = MLU_gen-MLU_student\n",
    "\n",
    "    bigrams = nltk.ngrams(tokens, 2)\n",
    "    trigrams = nltk.ngrams(tokens, 3)\n",
    "    ngram_list = (list(bigrams) + list(trigrams))\n",
    "    ngram_score = 0\n",
    "    for ngram in ngram_list:\n",
    "        if ' '.join(ngram) in ngram_texts:\n",
    "            # print(ngram, ngram_texts.index(' '.join(ngram)), ngram_coeffs[ngram_texts.index(' '.join(ngram))])\n",
    "            ngram_score += ngram_coeffs[ngram_texts.index(' '.join(ngram))]\n",
    "    gen_base_score['ngram_score'] = ngram_score\n",
    "\n",
    "\n",
    "    if(len(gen) and len(ref)): # to not include empty ones\n",
    "        result1 = {'generated': gen, 'reference': ref}\n",
    "        result4 = {'generated': gen, 'reference': ref}\n",
    "        result1['score'] = bleu.compute(predictions=[gen], references=[ref], max_order=1)\n",
    "        result4['score'] = bleu.compute(predictions=[gen], references=[ref], max_order=4)\n",
    "\n",
    "        gen_base_score['bleu1'] = result1['score']['bleu']\n",
    "        gen_base_score['bleu4'] = result4['score']['bleu']\n",
    "    else:\n",
    "        gen_base_score['bleu1'] = 0\n",
    "        gen_base_score['bleu4'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu-1</th>\n",
       "      <th>bleu-4</th>\n",
       "      <th>bertscore</th>\n",
       "      <th>rpt</th>\n",
       "      <th>overlap</th>\n",
       "      <th>matching</th>\n",
       "      <th>ngram_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [bleu-1, bleu-4, bertscore, rpt, overlap, matching, ngram_score]\n",
       "Index: []"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results = pd.DataFrame(columns=['bleu-1', 'bleu-4', 'bertscore', 'overlap', 'matching', 'ngram_score'])\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results['bleu-1'] = {\n",
    "    \"base\": round(np.mean([score['bleu1'] for score in generations_base_scores]), 4),\n",
    "    \"complex\": round(np.mean([score['bleu1'] for score in generation_scores]), 4),\n",
    "    \"ref\": None\n",
    "}\n",
    "all_results['bleu-4'] = {\n",
    "    \"base\": round(np.mean([score['bleu4'] for score in generations_base_scores]), 4),\n",
    "    \"complex\": round(np.mean([score['bleu4'] for score in generation_scores]), 4),\n",
    "    \"ref\": None,\n",
    "}\n",
    "all_results['bertscore'] = {\n",
    "    \"base\": round(np.mean([score['bertscore_f1'] for score in generations_base_scores]), 4),\n",
    "    \"complex\": round(np.mean([score['bertscore_f1'] for score in generation_scores]), 4),\n",
    "    \"ref\": None\n",
    "}\n",
    "all_results['overlap'] = {\n",
    "    \"base\": round(np.mean([score['overlap'] for score in generations_base_scores]), 4),\n",
    "    \"complex\": round(np.mean([score['overlap'] for score in generation_scores]), 4),\n",
    "    \"ref\": round(np.mean([score['overlap'] for score in reference_scores]), 4)\n",
    "}\n",
    "all_results['matching'] = {\n",
    "    \"base\": round(np.mean([score['MLU_match'] for score in generations_base_scores]), 4),\n",
    "    \"complex\": round(np.mean([score['MLU_match'] for score in generation_scores]), 4),\n",
    "    \"ref\": round(np.mean([score['MLU_match'] for score in reference_scores]), 4)\n",
    "}\n",
    "all_results['ngram_score'] = {\n",
    "    \"base\": round(np.mean([score['ngram_score'] for score in generations_base_scores]), 4),\n",
    "    \"complex\": round(np.mean([score['ngram_score'] for score in generation_scores]), 4),\n",
    "    \"ref\": round(np.mean([score['ngram_score'] for score in reference_scores]), 4)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bleu-1</th>\n",
       "      <th>bleu-4</th>\n",
       "      <th>bertscore</th>\n",
       "      <th>rpt</th>\n",
       "      <th>overlap</th>\n",
       "      <th>matching</th>\n",
       "      <th>ngram_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>base</th>\n",
       "      <td>0.1313</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.8328</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.0653</td>\n",
       "      <td>35.1402</td>\n",
       "      <td>0.2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complex</th>\n",
       "      <td>0.1247</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.8369</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.0661</td>\n",
       "      <td>20.8547</td>\n",
       "      <td>0.1313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>16.2331</td>\n",
       "      <td>0.0632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bleu-1  bleu-4  bertscore    rpt  overlap  matching  ngram_score\n",
       "base     0.1313  0.0045     0.8328  0.088   0.0653   35.1402       0.2009\n",
       "complex  0.1247  0.0025     0.8369  0.088   0.0661   20.8547       0.1313\n",
       "ref         NaN     NaN        NaN  0.088   0.0523   16.2331       0.0632"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mall_results\u001B[49m\u001B[38;5;241m.\u001B[39mT\u001B[38;5;241m.\u001B[39mto_latex(float_format\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%.4f\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, na_rep\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'all_results' is not defined"
     ]
    }
   ],
   "source": [
    "print(all_results.T.to_latex(float_format=\"%.4f\", na_rep=\"-\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Sure, it comes with practice! Don't give up. It does take a few tries to get comfortable with the poses and breathing techniques. Try to do 15 minutes per day. You'll get there with persistence and before you know it, you'll see the benefits!\",\n",
       "  'overlap': 0.0,\n",
       "  'MLU_match': 31.8,\n",
       "  'ngram_score': 0.413582684192269,\n",
       "  'rpt': 0.08346192000000001,\n",
       "  'bleu1': 0.15686274509803924,\n",
       "  'bleu4': 0.0,\n",
       "  'bertscore_f1': 0.8302353024482727,\n",
       "  'reference': \"Just to note, practice as a verb is an American spelling, the British one is practise. I should have used 'practise', sorry!\",\n",
       "  'context': \"So I know her because of Ihor. And now she does online sessions.<|endoftext|>ah, brilliant!<|endoftext|>Sometimes it's yoga, sometimes it's pilates. And I decide to join. Two times per week. I like it.<|endoftext|>I started doing yoga in Kyiv back in 2014. It was not an easy year as you remember and I really appreciated the relaxing effects of yoga. And I have been practicing ever since!<|endoftext|>And even bought a fitness mat, ball and top for sessions ).<|endoftext|>Do you practice at home?<|endoftext|>Do you practice yourself now? Yes, I practice at home usually. One time at the office )).<|endoftext|>I do, yes, I follow a couple of yoga youtube channels and do the sessions from there.<|endoftext|>Is it hard? Because I thought about more yoga or pilates.<|endoftext|>\"},\n",
       " {'text': 'Great! Yoga practice has a lot of benefits. How about your listening and speaking skills? Would you like to practice these using a native English speaker?',\n",
       "  'overlap': 0.047619047619047616,\n",
       "  'MLU_match': 11.8,\n",
       "  'ngram_score': -0.23984571315131742,\n",
       "  'rpt': 0.1160505,\n",
       "  'bleu1': 0.10000000000000002,\n",
       "  'bleu4': 0.0,\n",
       "  'bertscore_f1': 0.8552031517028809,\n",
       "  'reference': \"And the noun is practice. as in 'regular yoga practice is wonderful for you'.\",\n",
       "  'context': \"Sometimes it's yoga, sometimes it's pilates. And I decide to join. Two times per week. I like it.<|endoftext|>I started doing yoga in Kyiv back in 2014. It was not an easy year as you remember and I really appreciated the relaxing effects of yoga. And I have been practicing ever since!<|endoftext|>And even bought a fitness mat, ball and top for sessions ).<|endoftext|>Do you practice at home?<|endoftext|>Do you practice yourself now? Yes, I practice at home usually. One time at the office )).<|endoftext|>I do, yes, I follow a couple of yoga youtube channels and do the sessions from there.<|endoftext|>Is it hard? Because I thought about more yoga or pilates.<|endoftext|>Just to note, practice as a verb is an American spelling, the British one is practise. I should have used 'practise', sorry!<|endoftext|>For example, two times with this girl <YOGA INSTRUCTOR> and one time myself.<|endoftext|>\"},\n",
       " {'text': 'Yes, practice is another helpful practice to build up your English skills.',\n",
       "  'overlap': 0.125,\n",
       "  'MLU_match': 0.8000000000000007,\n",
       "  'ngram_score': -0.008942568029654659,\n",
       "  'rpt': 0.08435975000000001,\n",
       "  'bleu1': 0.05255420588163462,\n",
       "  'bleu4': 0.0,\n",
       "  'bertscore_f1': 0.8497314453125,\n",
       "  'reference': 'I like that I can choose easier or harder sessions. It depends whether you want to spell it in a British or American way)).',\n",
       "  'context': \"And even bought a fitness mat, ball and top for sessions ).<|endoftext|>Do you practice at home?<|endoftext|>Do you practice yourself now? Yes, I practice at home usually. One time at the office )).<|endoftext|>I do, yes, I follow a couple of yoga youtube channels and do the sessions from there.<|endoftext|>Is it hard? Because I thought about more yoga or pilates.<|endoftext|>Just to note, practice as a verb is an American spelling, the British one is practise. I should have used 'practise', sorry!<|endoftext|>For example, two times with this girl <YOGA INSTRUCTOR> and one time myself.<|endoftext|>And the noun is practice. as in 'regular yoga practice is wonderful for you'.<|endoftext|>Should I use practice too?<|endoftext|>\"},\n",
       " {'text': \"Oh, you might enjoy this video, but don't try the poses at home, especially not with those IKEA chairs!).\",\n",
       "  'overlap': 0.0625,\n",
       "  'MLU_match': 10.2,\n",
       "  'ngram_score': -0.3470567451400328,\n",
       "  'rpt': 0.09020999999999998,\n",
       "  'bleu1': 0.1476986154218617,\n",
       "  'bleu4': 0.0,\n",
       "  'bertscore_f1': 0.8324360251426697,\n",
       "  'reference': 'No! Tell me. Both are good, did you see and did you watch. and Have you seen? would be even better.',\n",
       "  'context': \"Is it hard? Because I thought about more yoga or pilates.<|endoftext|>Just to note, practice as a verb is an American spelling, the British one is practise. I should have used 'practise', sorry!<|endoftext|>For example, two times with this girl <YOGA INSTRUCTOR> and one time myself.<|endoftext|>And the noun is practice. as in 'regular yoga practice is wonderful for you'.<|endoftext|>Should I use practice too?<|endoftext|>I like that I can choose easier or harder sessions. It depends whether you want to spell it in a British or American way)).<|endoftext|>practise. ahaha, it's autocorrect. actually.<|endoftext|>It's actually a good thing about this programme, there is no autocorrect, so we have spell everything out ourselves :). *have to spell.<|endoftext|><TEACHER>! Did you see an advert with yoga from IKEA? did you watch? hm.<|endoftext|>\"},\n",
       " {'text': \"Correct! You got it! 'Have been married' means they were married in the past and are not married now. 'Were married' is the same meaning. Great job! You're learning fast. Keep it up!\",\n",
       "  'overlap': 0.09090909090909091,\n",
       "  'MLU_match': 25.2,\n",
       "  'ngram_score': 0.8471944588862244,\n",
       "  'rpt': 0.11968914,\n",
       "  'bleu1': 0.225,\n",
       "  'bleu4': 0.0,\n",
       "  'bertscore_f1': 0.8607983589172363,\n",
       "  'reference': \"Oooh, sorry, let's go back. I can see where we slipped. have been married - present perfect. It's a present tense, they are still married at present!\",\n",
       "  'context': \")).<|endoftext|>They have been married for 5 years. vs. They were married for 5 years. What's the difference/. ?<|endoftext|>And if I'm not doing now It's 'have done'. have been married - ah. yes. this for. They are not married now.<|endoftext|>yes, correct! and if 'they were married'?<|endoftext|>we don't know? I mean about now.<|endoftext|>Mmm, no, they probably got a divorce or someone died.<|endoftext|>hm.<|endoftext|>like Nicole Kidman and Tom Cruise! they were married.<|endoftext|>So 'have been married'- they are not merried now. were married - same?<|endoftext|>\"}]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_scores[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"Just to note, practice as a verb is an American spelling, the British one is practise. I should have used 'practise', sorry!\",\n",
       "  'overlap': 0.0,\n",
       "  'MLU_match': 7.800000000000001,\n",
       "  'ngram_score': 0.46713450189846545,\n",
       "  'bleu1': 1,\n",
       "  'bleu4': 1,\n",
       "  'bertscore_f1': 1,\n",
       "  'rpt': 0.08346192000000001},\n",
       " {'text': \"And the noun is practice. as in 'regular yoga practice is wonderful for you'.\",\n",
       "  'overlap': 0.08333333333333333,\n",
       "  'MLU_match': -0.1999999999999993,\n",
       "  'ngram_score': -0.02643475191698528,\n",
       "  'bleu1': 1,\n",
       "  'bleu4': 1,\n",
       "  'bertscore_f1': 1,\n",
       "  'rpt': 0.1160505},\n",
       " {'text': 'I like that I can choose easier or harder sessions. It depends whether you want to spell it in a British or American way)).',\n",
       "  'overlap': 0.0,\n",
       "  'MLU_match': 12.8,\n",
       "  'ngram_score': 0.35095014965583327,\n",
       "  'bleu1': 1,\n",
       "  'bleu4': 1,\n",
       "  'bertscore_f1': 1,\n",
       "  'rpt': 0.08435975000000001},\n",
       " {'text': 'No! Tell me. Both are good, did you see and did you watch. and Have you seen? would be even better.',\n",
       "  'overlap': 0.15384615384615385,\n",
       "  'MLU_match': 11.2,\n",
       "  'ngram_score': -0.31248915335754,\n",
       "  'bleu1': 1,\n",
       "  'bleu4': 1,\n",
       "  'bertscore_f1': 1,\n",
       "  'rpt': 0.09020999999999998},\n",
       " {'text': \"Oooh, sorry, let's go back. I can see where we slipped. have been married - present perfect. It's a present tense, they are still married at present!\",\n",
       "  'overlap': 0.07692307692307693,\n",
       "  'MLU_match': 19.2,\n",
       "  'ngram_score': -0.08768821566532874,\n",
       "  'bleu1': 1,\n",
       "  'bleu4': 1,\n",
       "  'bertscore_f1': 1,\n",
       "  'rpt': 0.11968914}]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_scores[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}