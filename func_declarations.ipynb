{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "import contractions\n",
    "import json\n",
    "\n",
    "from autocorrect import Speller\n",
    "from nltk.corpus import stopwords, words\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import r2_score\n",
    "from collections import Counter\n",
    "from readability import Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path = 'TeacherStudentChatroomCorpus_v2/public'\n",
    "filenames = glob.glob(path+\"/*.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['figs/student/student002_MLU_AoA.png',\n",
       " 'figs/student/student002_TTR_utterances_words_scaffolding_proportion.png',\n",
       " 'figs/student/student002_WF.png',\n",
       " 'figs/student/student003_MLU_AoA.png',\n",
       " 'figs/student/student003_TTR_utterances_words_scaffolding_proportion.png',\n",
       " 'figs/student/student003_WF.png',\n",
       " 'figs/student/student004_MLU_AoA.png',\n",
       " 'figs/student/student004_TTR_utterances_words_scaffolding_proportion.png',\n",
       " 'figs/student/student004_WF.png',\n",
       " 'figs/student/student005_MLU_AoA.png',\n",
       " 'figs/student/student005_TTR_utterances_words_scaffolding_proportion.png',\n",
       " 'figs/student/student005_WF.png',\n",
       " 'figs/student/student006_MLU_AoA.png',\n",
       " 'figs/student/student006_TTR_utterances_words_scaffolding_proportion.png',\n",
       " 'figs/student/student006_WF.png',\n",
       " 'figs/student/student007_MLU_AoA.png',\n",
       " 'figs/student/student007_TTR_utterances_words_scaffolding_proportion.png',\n",
       " 'figs/student/student007_WF.png',\n",
       " 'figs/student/student009_MLU_AoA.png',\n",
       " 'figs/student/student009_TTR_utterances_words_scaffolding_proportion.png',\n",
       " 'figs/student/student009_WF.png',\n",
       " 'figs/student/student010_MLU_AoA.png',\n",
       " 'figs/student/student010_TTR_utterances_words_scaffolding_proportion.png',\n",
       " 'figs/student/student010_WF.png',\n",
       " 'figs/student/student011_MLU_AoA.png',\n",
       " 'figs/student/student011_TTR_utterances_words_scaffolding_proportion.png',\n",
       " 'figs/student/student011_WF.png',\n",
       " 'figs/student/student012_MLU_AoA.png',\n",
       " 'figs/student/student012_TTR_utterances_words_scaffolding_proportion.png',\n",
       " 'figs/student/student012_WF.png',\n",
       " 'figs/student/student014_MLU_AoA.png',\n",
       " 'figs/student/student014_TTR_utterances_words_scaffolding_proportion.png',\n",
       " 'figs/student/student014_WF.png',\n",
       " 'figs/student/student015_MLU_AoA.png',\n",
       " 'figs/student/student015_TTR_utterances_words_scaffolding_proportion.png',\n",
       " 'figs/student/student015_WF.png']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_names = glob.glob('plots/student'+\"/*\")\n",
    "img_names = ['figs/student/'+name.split('\\\\')[1] for name in img_names]\n",
    "img_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student002_MLU_AoA.png} \n",
      "    \\caption{figs/student/student002 MLU AoA} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student002_TTR_utterances_words_scaffolding_proportion.png} \n",
      "    \\caption{figs/student/student002 TTR utterances words scaffolding proportion} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student002_WF.png} \n",
      "    \\caption{figs/student/student002 WF} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student003_MLU_AoA.png} \n",
      "    \\caption{figs/student/student003 MLU AoA} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student003_TTR_utterances_words_scaffolding_proportion.png} \n",
      "    \\caption{figs/student/student003 TTR utterances words scaffolding proportion} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student003_WF.png} \n",
      "    \\caption{figs/student/student003 WF} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student004_MLU_AoA.png} \n",
      "    \\caption{figs/student/student004 MLU AoA} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student004_TTR_utterances_words_scaffolding_proportion.png} \n",
      "    \\caption{figs/student/student004 TTR utterances words scaffolding proportion} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student004_WF.png} \n",
      "    \\caption{figs/student/student004 WF} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student005_MLU_AoA.png} \n",
      "    \\caption{figs/student/student005 MLU AoA} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student005_TTR_utterances_words_scaffolding_proportion.png} \n",
      "    \\caption{figs/student/student005 TTR utterances words scaffolding proportion} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student005_WF.png} \n",
      "    \\caption{figs/student/student005 WF} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student006_MLU_AoA.png} \n",
      "    \\caption{figs/student/student006 MLU AoA} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student006_TTR_utterances_words_scaffolding_proportion.png} \n",
      "    \\caption{figs/student/student006 TTR utterances words scaffolding proportion} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student006_WF.png} \n",
      "    \\caption{figs/student/student006 WF} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student007_MLU_AoA.png} \n",
      "    \\caption{figs/student/student007 MLU AoA} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student007_TTR_utterances_words_scaffolding_proportion.png} \n",
      "    \\caption{figs/student/student007 TTR utterances words scaffolding proportion} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student007_WF.png} \n",
      "    \\caption{figs/student/student007 WF} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student009_MLU_AoA.png} \n",
      "    \\caption{figs/student/student009 MLU AoA} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student009_TTR_utterances_words_scaffolding_proportion.png} \n",
      "    \\caption{figs/student/student009 TTR utterances words scaffolding proportion} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student009_WF.png} \n",
      "    \\caption{figs/student/student009 WF} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student010_MLU_AoA.png} \n",
      "    \\caption{figs/student/student010 MLU AoA} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student010_TTR_utterances_words_scaffolding_proportion.png} \n",
      "    \\caption{figs/student/student010 TTR utterances words scaffolding proportion} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student010_WF.png} \n",
      "    \\caption{figs/student/student010 WF} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student011_MLU_AoA.png} \n",
      "    \\caption{figs/student/student011 MLU AoA} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student011_TTR_utterances_words_scaffolding_proportion.png} \n",
      "    \\caption{figs/student/student011 TTR utterances words scaffolding proportion} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student011_WF.png} \n",
      "    \\caption{figs/student/student011 WF} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student012_MLU_AoA.png} \n",
      "    \\caption{figs/student/student012 MLU AoA} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student012_TTR_utterances_words_scaffolding_proportion.png} \n",
      "    \\caption{figs/student/student012 TTR utterances words scaffolding proportion} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student012_WF.png} \n",
      "    \\caption{figs/student/student012 WF} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student014_MLU_AoA.png} \n",
      "    \\caption{figs/student/student014 MLU AoA} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student014_TTR_utterances_words_scaffolding_proportion.png} \n",
      "    \\caption{figs/student/student014 TTR utterances words scaffolding proportion} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student014_WF.png} \n",
      "    \\caption{figs/student/student014 WF} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student015_MLU_AoA.png} \n",
      "    \\caption{figs/student/student015 MLU AoA} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student015_TTR_utterances_words_scaffolding_proportion.png} \n",
      "    \\caption{figs/student/student015 TTR utterances words scaffolding proportion} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \\begin{subfigure}{0.3\\textwidth} \n",
      "    \\includegraphics[width=\\textwidth]{figs/student/student015_WF.png} \n",
      "    \\caption{figs/student/student015 WF} \n",
      "    \\end{subfigure} \n",
      "    \\hfill \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "latex_code = \"\"\n",
    "\n",
    "for image_name in img_names:\n",
    "    student_id = image_name.split(\"_\")[0]\n",
    "    aspect = ' '.join(image_name.split(\"_\")[1:]).split('.')[0]\n",
    "\n",
    "    latex_code += r\"\"\"\\begin{subfigure}{0.3\\textwidth} \n",
    "    \\includegraphics[width=\\textwidth]{\"\"\" + image_name + r\"\"\"} \n",
    "    \\caption{\"\"\" + student_id + \" \" + aspect +  r\"\"\"} \n",
    "    \\end{subfigure} \n",
    "    \\hfill \n",
    "    \"\"\"\n",
    "\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user.id</th>\n",
       "      <th>role</th>\n",
       "      <th>turn.number</th>\n",
       "      <th>anonymised</th>\n",
       "      <th>edited</th>\n",
       "      <th>responding.to</th>\n",
       "      <th>sequence</th>\n",
       "      <th>seq.type</th>\n",
       "      <th>focus</th>\n",
       "      <th>resource</th>\n",
       "      <th>assessment</th>\n",
       "      <th>nWords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-11-17 12:00:08</td>\n",
       "      <td>teacher001</td>\n",
       "      <td>teacher</td>\n",
       "      <td>1</td>\n",
       "      <td>Hi &lt;STUDENT&gt;, hope I didn't get you up too early!</td>\n",
       "      <td>Hi &lt;STUDENT&gt;, hope I didn't get you up too early!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>opening</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-11-17 12:01:08</td>\n",
       "      <td>student002</td>\n",
       "      <td>student</td>\n",
       "      <td>2</td>\n",
       "      <td>Don't worry, my exam is on next Saturday, so I...</td>\n",
       "      <td>Don't worry, my exam is next Saturday, so I sh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-11-17 12:01:37</td>\n",
       "      <td>teacher001</td>\n",
       "      <td>teacher</td>\n",
       "      <td>3</td>\n",
       "      <td>Ah OK, so good practice then...is that an IELT...</td>\n",
       "      <td>Ah OK, so good practice then...is that an IELT...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>topic opening</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-11-17 12:01:52</td>\n",
       "      <td>student002</td>\n",
       "      <td>student</td>\n",
       "      <td>4</td>\n",
       "      <td>Exactly.</td>\n",
       "      <td>Exactly.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-17 12:02:11</td>\n",
       "      <td>teacher001</td>\n",
       "      <td>teacher</td>\n",
       "      <td>5</td>\n",
       "      <td>I've lost track of how many you've done</td>\n",
       "      <td>I've lost track of how many you've done</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2019-11-17 13:01:33</td>\n",
       "      <td>teacher001</td>\n",
       "      <td>teacher</td>\n",
       "      <td>88</td>\n",
       "      <td>OK thank's &lt;STUDENT&gt; -we'll leave it there ok?...</td>\n",
       "      <td>OK thank's &lt;STUDENT&gt; -we'll leave it there ok?...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>closing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2019-11-17 13:01:51</td>\n",
       "      <td>student002</td>\n",
       "      <td>student</td>\n",
       "      <td>89</td>\n",
       "      <td>Okay, thank you!!</td>\n",
       "      <td>Okay, thank you!!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2019-11-17 13:02:08</td>\n",
       "      <td>teacher001</td>\n",
       "      <td>teacher</td>\n",
       "      <td>90</td>\n",
       "      <td>I'll be in touch - feel free to send me an ema...</td>\n",
       "      <td>I'll be in touch - feel free to send me an ema...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2019-11-17 13:02:27</td>\n",
       "      <td>student002</td>\n",
       "      <td>student</td>\n",
       "      <td>91</td>\n",
       "      <td>Sure, see you.</td>\n",
       "      <td>Sure, see you.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2019-11-17 13:02:32</td>\n",
       "      <td>teacher001</td>\n",
       "      <td>teacher</td>\n",
       "      <td>92</td>\n",
       "      <td>OK bye...</td>\n",
       "      <td>OK bye...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              timestamp     user.id     role  turn.number  \\\n",
       "0   2019-11-17 12:00:08  teacher001  teacher            1   \n",
       "1   2019-11-17 12:01:08  student002  student            2   \n",
       "2   2019-11-17 12:01:37  teacher001  teacher            3   \n",
       "3   2019-11-17 12:01:52  student002  student            4   \n",
       "4   2019-11-17 12:02:11  teacher001  teacher            5   \n",
       "..                  ...         ...      ...          ...   \n",
       "87  2019-11-17 13:01:33  teacher001  teacher           88   \n",
       "88  2019-11-17 13:01:51  student002  student           89   \n",
       "89  2019-11-17 13:02:08  teacher001  teacher           90   \n",
       "90  2019-11-17 13:02:27  student002  student           91   \n",
       "91  2019-11-17 13:02:32  teacher001  teacher           92   \n",
       "\n",
       "                                           anonymised  \\\n",
       "0   Hi <STUDENT>, hope I didn't get you up too early!   \n",
       "1   Don't worry, my exam is on next Saturday, so I...   \n",
       "2   Ah OK, so good practice then...is that an IELT...   \n",
       "3                                            Exactly.   \n",
       "4             I've lost track of how many you've done   \n",
       "..                                                ...   \n",
       "87  OK thank's <STUDENT> -we'll leave it there ok?...   \n",
       "88                                  Okay, thank you!!   \n",
       "89  I'll be in touch - feel free to send me an ema...   \n",
       "90                                     Sure, see you.   \n",
       "91                                          OK bye...   \n",
       "\n",
       "                                               edited responding.to sequence  \\\n",
       "0   Hi <STUDENT>, hope I didn't get you up too early!           NaN      1.0   \n",
       "1   Don't worry, my exam is next Saturday, so I sh...           NaN      NaN   \n",
       "2   Ah OK, so good practice then...is that an IELT...           NaN      2.0   \n",
       "3                                            Exactly.           NaN      NaN   \n",
       "4             I've lost track of how many you've done           NaN      NaN   \n",
       "..                                                ...           ...      ...   \n",
       "87  OK thank's <STUDENT> -we'll leave it there ok?...           NaN      9.0   \n",
       "88                                  Okay, thank you!!           NaN      NaN   \n",
       "89  I'll be in touch - feel free to send me an ema...           NaN      NaN   \n",
       "90                                     Sure, see you.           NaN      NaN   \n",
       "91                                          OK bye...           NaN      NaN   \n",
       "\n",
       "         seq.type focus  resource assessment  nWords  \n",
       "0         opening   NaN       NaN        NaN      10  \n",
       "1             NaN   NaN       NaN        NaN      14  \n",
       "2   topic opening   NaN       NaN        NaN      10  \n",
       "3             NaN   NaN       NaN        NaN       1  \n",
       "4             NaN   NaN       NaN        NaN       8  \n",
       "..            ...   ...       ...        ...     ...  \n",
       "87        closing   NaN       NaN        NaN      14  \n",
       "88            NaN   NaN       NaN        NaN       3  \n",
       "89            NaN   NaN       NaN        NaN      13  \n",
       "90            NaN   NaN       NaN        NaN       3  \n",
       "91            NaN   NaN       NaN         B1       2  \n",
       "\n",
       "[92 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatrooms = []\n",
    "for filename in filenames:\n",
    "    chatrooms.append(pd.read_csv(filename, sep='\\t'))\n",
    "\n",
    "chatrooms_all = pd.concat(chatrooms, axis=0, ignore_index=True)\n",
    "chatrooms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chat.num</th>\n",
       "      <th>filename</th>\n",
       "      <th>start.time</th>\n",
       "      <th>teacher</th>\n",
       "      <th>student</th>\n",
       "      <th>n.turns</th>\n",
       "      <th>n.teacher.turns</th>\n",
       "      <th>n.student.turns</th>\n",
       "      <th>n.words</th>\n",
       "      <th>n.teacher.words</th>\n",
       "      <th>n.student.words</th>\n",
       "      <th>student.cefr.level</th>\n",
       "      <th>student.age</th>\n",
       "      <th>student.L1</th>\n",
       "      <th>student.immersed.in.english</th>\n",
       "      <th>is_sett_annotated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>teacherstudentchat00002.tsv</td>\n",
       "      <td>2019-11-17 12:00:08</td>\n",
       "      <td>teacher001</td>\n",
       "      <td>student002</td>\n",
       "      <td>92</td>\n",
       "      <td>52</td>\n",
       "      <td>40</td>\n",
       "      <td>1067</td>\n",
       "      <td>767</td>\n",
       "      <td>300</td>\n",
       "      <td>B1</td>\n",
       "      <td>22</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>teacherstudentchat00003.tsv</td>\n",
       "      <td>2019-12-03 13:00:03</td>\n",
       "      <td>teacher001</td>\n",
       "      <td>student004</td>\n",
       "      <td>115</td>\n",
       "      <td>55</td>\n",
       "      <td>60</td>\n",
       "      <td>1623</td>\n",
       "      <td>943</td>\n",
       "      <td>680</td>\n",
       "      <td>C1</td>\n",
       "      <td>40</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>teacherstudentchat00004.tsv</td>\n",
       "      <td>2019-12-03 15:29:58</td>\n",
       "      <td>teacher001</td>\n",
       "      <td>student003</td>\n",
       "      <td>96</td>\n",
       "      <td>51</td>\n",
       "      <td>45</td>\n",
       "      <td>1320</td>\n",
       "      <td>965</td>\n",
       "      <td>355</td>\n",
       "      <td>B2</td>\n",
       "      <td>32</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>teacherstudentchat00005.tsv</td>\n",
       "      <td>2019-12-04 14:01:25</td>\n",
       "      <td>teacher001</td>\n",
       "      <td>student002</td>\n",
       "      <td>75</td>\n",
       "      <td>43</td>\n",
       "      <td>32</td>\n",
       "      <td>1121</td>\n",
       "      <td>936</td>\n",
       "      <td>185</td>\n",
       "      <td>B1</td>\n",
       "      <td>22</td>\n",
       "      <td>Japanese</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>teacherstudentchat00006.tsv</td>\n",
       "      <td>2019-12-09 13:00:35</td>\n",
       "      <td>teacher001</td>\n",
       "      <td>student004</td>\n",
       "      <td>138</td>\n",
       "      <td>75</td>\n",
       "      <td>63</td>\n",
       "      <td>1820</td>\n",
       "      <td>1109</td>\n",
       "      <td>711</td>\n",
       "      <td>C1</td>\n",
       "      <td>40</td>\n",
       "      <td>Spanish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>257</td>\n",
       "      <td>teacherstudentchat00257.tsv</td>\n",
       "      <td>2021-06-10 23:00:00</td>\n",
       "      <td>teacher008</td>\n",
       "      <td>student009</td>\n",
       "      <td>145</td>\n",
       "      <td>69</td>\n",
       "      <td>76</td>\n",
       "      <td>1688</td>\n",
       "      <td>1099</td>\n",
       "      <td>589</td>\n",
       "      <td>B2</td>\n",
       "      <td>12</td>\n",
       "      <td>Ukrainian</td>\n",
       "      <td>n</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>258</td>\n",
       "      <td>teacherstudentchat00258.tsv</td>\n",
       "      <td>2021-06-15 11:01:30</td>\n",
       "      <td>teacher008</td>\n",
       "      <td>student014</td>\n",
       "      <td>103</td>\n",
       "      <td>59</td>\n",
       "      <td>44</td>\n",
       "      <td>1659</td>\n",
       "      <td>975</td>\n",
       "      <td>684</td>\n",
       "      <td>C2</td>\n",
       "      <td>30</td>\n",
       "      <td>Italian</td>\n",
       "      <td>n</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>259</td>\n",
       "      <td>teacherstudentchat00259.tsv</td>\n",
       "      <td>2021-06-17 12:17:50</td>\n",
       "      <td>teacher008</td>\n",
       "      <td>student012</td>\n",
       "      <td>150</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>1201</td>\n",
       "      <td>738</td>\n",
       "      <td>463</td>\n",
       "      <td>C2</td>\n",
       "      <td>33</td>\n",
       "      <td>Russian</td>\n",
       "      <td>n</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>260</td>\n",
       "      <td>teacherstudentchat00260.tsv</td>\n",
       "      <td>2021-06-18 09:38:19</td>\n",
       "      <td>teacher008</td>\n",
       "      <td>student011</td>\n",
       "      <td>183</td>\n",
       "      <td>77</td>\n",
       "      <td>106</td>\n",
       "      <td>1318</td>\n",
       "      <td>744</td>\n",
       "      <td>574</td>\n",
       "      <td>B2</td>\n",
       "      <td>26</td>\n",
       "      <td>Russian,Ukrainian</td>\n",
       "      <td>n</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>261</td>\n",
       "      <td>teacherstudentchat00261.tsv</td>\n",
       "      <td>2021-06-18 09:38:19</td>\n",
       "      <td>teacher008</td>\n",
       "      <td>student011</td>\n",
       "      <td>183</td>\n",
       "      <td>77</td>\n",
       "      <td>106</td>\n",
       "      <td>1318</td>\n",
       "      <td>744</td>\n",
       "      <td>574</td>\n",
       "      <td>B2</td>\n",
       "      <td>26</td>\n",
       "      <td>Russian,Ukrainian</td>\n",
       "      <td>n</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>260 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     chat.num                     filename           start.time     teacher  \\\n",
       "0           2  teacherstudentchat00002.tsv  2019-11-17 12:00:08  teacher001   \n",
       "1           3  teacherstudentchat00003.tsv  2019-12-03 13:00:03  teacher001   \n",
       "2           4  teacherstudentchat00004.tsv  2019-12-03 15:29:58  teacher001   \n",
       "3           5  teacherstudentchat00005.tsv  2019-12-04 14:01:25  teacher001   \n",
       "4           6  teacherstudentchat00006.tsv  2019-12-09 13:00:35  teacher001   \n",
       "..        ...                          ...                  ...         ...   \n",
       "255       257  teacherstudentchat00257.tsv  2021-06-10 23:00:00  teacher008   \n",
       "256       258  teacherstudentchat00258.tsv  2021-06-15 11:01:30  teacher008   \n",
       "257       259  teacherstudentchat00259.tsv  2021-06-17 12:17:50  teacher008   \n",
       "258       260  teacherstudentchat00260.tsv  2021-06-18 09:38:19  teacher008   \n",
       "259       261  teacherstudentchat00261.tsv  2021-06-18 09:38:19  teacher008   \n",
       "\n",
       "        student  n.turns  n.teacher.turns  n.student.turns  n.words  \\\n",
       "0    student002       92               52               40     1067   \n",
       "1    student004      115               55               60     1623   \n",
       "2    student003       96               51               45     1320   \n",
       "3    student002       75               43               32     1121   \n",
       "4    student004      138               75               63     1820   \n",
       "..          ...      ...              ...              ...      ...   \n",
       "255  student009      145               69               76     1688   \n",
       "256  student014      103               59               44     1659   \n",
       "257  student012      150               75               75     1201   \n",
       "258  student011      183               77              106     1318   \n",
       "259  student011      183               77              106     1318   \n",
       "\n",
       "     n.teacher.words  n.student.words student.cefr.level  student.age  \\\n",
       "0                767              300                 B1           22   \n",
       "1                943              680                 C1           40   \n",
       "2                965              355                 B2           32   \n",
       "3                936              185                 B1           22   \n",
       "4               1109              711                 C1           40   \n",
       "..               ...              ...                ...          ...   \n",
       "255             1099              589                 B2           12   \n",
       "256              975              684                 C2           30   \n",
       "257              738              463                 C2           33   \n",
       "258              744              574                 B2           26   \n",
       "259              744              574                 B2           26   \n",
       "\n",
       "            student.L1 student.immersed.in.english  is_sett_annotated  \n",
       "0             Japanese                         NaN               True  \n",
       "1              Spanish                         NaN               True  \n",
       "2             Japanese                         NaN               True  \n",
       "3             Japanese                         NaN               True  \n",
       "4              Spanish                         NaN               True  \n",
       "..                 ...                         ...                ...  \n",
       "255          Ukrainian                           n              False  \n",
       "256            Italian                           n              False  \n",
       "257            Russian                           n              False  \n",
       "258  Russian,Ukrainian                           n              False  \n",
       "259  Russian,Ukrainian                           n              False  \n",
       "\n",
       "[260 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv(path+\"/teacherStudentChatroomCorpusPublicMetadata.csv\")\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'admin',\n",
       " 'clarification',\n",
       " 'closing',\n",
       " 'disruption',\n",
       " 'eliciting',\n",
       " 'enquiry',\n",
       " 'exercise',\n",
       " 'free practice',\n",
       " 'homework',\n",
       " 'non-English',\n",
       " 'opening',\n",
       " 'presentation',\n",
       " 'recap',\n",
       " 'redirection',\n",
       " 'reference',\n",
       " 'repair',\n",
       " 'revision',\n",
       " 'scaffolding',\n",
       " 'topic closure',\n",
       " 'topic development',\n",
       " 'topic opening'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_types = chatrooms_all['seq.type']\n",
    "seq_types.dropna(inplace=True)\n",
    "seq_types = seq_types.unique()\n",
    "unique_seq_types=[]\n",
    "for seq_type in seq_types:\n",
    "    for type_split in seq_type.split(','):\n",
    "        unique_seq_types.append(type_split)\n",
    "unique_seq_types = set(unique_seq_types)\n",
    "unique_seq_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "student_group = metadata.groupby(\"student\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 28, 6, 4, 32, 48, 14, 51, 26, 26, 18]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[int(item) for item  in student_group['chat.num'].describe()['count'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "student007_chats = []\n",
    "for chat in chatrooms:\n",
    "    for id in chat['user.id']:\n",
    "        if id == 'student007':\n",
    "            student007_chats.append(chat)\n",
    "            break\n",
    "chatC1 = pd.read_csv(path+\"/teacherstudentchat00049.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "l1_groups = metadata.groupby('student.L1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Split the statistics by students' abilities (measured by CEFR for now)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B1: 35\n",
      "B2: 144\n",
      "C1: 29\n",
      "C2: 52\n"
     ]
    }
   ],
   "source": [
    "cefr_groups_meta = metadata.groupby('student.cefr.level')\n",
    "# chat number-2 = index in the chatrooms list\n",
    "\n",
    "cefr_groups = {}\n",
    "for group, contents in cefr_groups_meta:\n",
    "    cefr_groups[group] = []\n",
    "    for chat_num in contents['chat.num']:\n",
    "        cefr_groups[group].append(chatrooms[chat_num-2])\n",
    "    print(f'{group}: {len(cefr_groups[group])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>AoA_Kup_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>2.893384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>9.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abacus</td>\n",
       "      <td>8.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abacuses</td>\n",
       "      <td>8.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abalone</td>\n",
       "      <td>12.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51710</th>\n",
       "      <td>zucchini</td>\n",
       "      <td>6.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51711</th>\n",
       "      <td>zucchinis</td>\n",
       "      <td>6.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51712</th>\n",
       "      <td>zwieback</td>\n",
       "      <td>16.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51713</th>\n",
       "      <td>zygote</td>\n",
       "      <td>15.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51714</th>\n",
       "      <td>zygotes</td>\n",
       "      <td>15.380000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51715 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word  AoA_Kup_lem\n",
       "0              a     2.893384\n",
       "1       aardvark     9.890000\n",
       "2         abacus     8.690000\n",
       "3       abacuses     8.690000\n",
       "4        abalone    12.230000\n",
       "...          ...          ...\n",
       "51710   zucchini     6.790000\n",
       "51711  zucchinis     6.790000\n",
       "51712   zwieback    16.100000\n",
       "51713     zygote    15.380000\n",
       "51714    zygotes    15.380000\n",
       "\n",
       "[51715 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AoA_list = pd.read_excel('AoA/AoA_51715_words.xlsx')[['Word', 'AoA_Kup_lem']]\n",
    "AoA_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemRank</th>\n",
       "      <th>lemma</th>\n",
       "      <th>PoS</th>\n",
       "      <th>lemFreq</th>\n",
       "      <th>wordFreq</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>a</td>\n",
       "      <td>50033612</td>\n",
       "      <td>50033323</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>the</td>\n",
       "      <td>a</td>\n",
       "      <td>50033612</td>\n",
       "      <td>287</td>\n",
       "      <td>ze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>be</td>\n",
       "      <td>v</td>\n",
       "      <td>32394756</td>\n",
       "      <td>10093608</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>be</td>\n",
       "      <td>v</td>\n",
       "      <td>32394756</td>\n",
       "      <td>6848519</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>be</td>\n",
       "      <td>v</td>\n",
       "      <td>32394756</td>\n",
       "      <td>6303682</td>\n",
       "      <td>'s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11455</th>\n",
       "      <td>5048</td>\n",
       "      <td>wheat</td>\n",
       "      <td>n</td>\n",
       "      <td>11877</td>\n",
       "      <td>11769</td>\n",
       "      <td>wheat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11456</th>\n",
       "      <td>5048</td>\n",
       "      <td>wheat</td>\n",
       "      <td>n</td>\n",
       "      <td>11877</td>\n",
       "      <td>108</td>\n",
       "      <td>wheats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11457</th>\n",
       "      <td>5049</td>\n",
       "      <td>predator</td>\n",
       "      <td>n</td>\n",
       "      <td>11876</td>\n",
       "      <td>6799</td>\n",
       "      <td>predators</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11458</th>\n",
       "      <td>5049</td>\n",
       "      <td>predator</td>\n",
       "      <td>n</td>\n",
       "      <td>11876</td>\n",
       "      <td>5077</td>\n",
       "      <td>predator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11459</th>\n",
       "      <td>5050</td>\n",
       "      <td>bizarre</td>\n",
       "      <td>j</td>\n",
       "      <td>11875</td>\n",
       "      <td>11875</td>\n",
       "      <td>bizarre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11460 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lemRank     lemma PoS   lemFreq  wordFreq       word\n",
       "0            1       the   a  50033612  50033323        the\n",
       "1            1       the   a  50033612       287         ze\n",
       "2            2        be   v  32394756  10093608         is\n",
       "3            2        be   v  32394756   6848519        was\n",
       "4            2        be   v  32394756   6303682         's\n",
       "...        ...       ...  ..       ...       ...        ...\n",
       "11455     5048     wheat   n     11877     11769      wheat\n",
       "11456     5048     wheat   n     11877       108     wheats\n",
       "11457     5049  predator   n     11876      6799  predators\n",
       "11458     5049  predator   n     11876      5077   predator\n",
       "11459     5050   bizarre   j     11875     11875    bizarre\n",
       "\n",
       "[11460 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WF_list = pd.read_excel('wordFrequency.xlsx', '3 wordForms')\n",
    "WF_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoplist = stopwords.words('english') # remember - they are lowercase\n",
    "stoplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$: dollar\n",
      "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
      "'': closing quotation mark\n",
      "    ' ''\n",
      "(: opening parenthesis\n",
      "    ( [ {\n",
      "): closing parenthesis\n",
      "    ) ] }\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ! ?\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "CD: numeral, cardinal\n",
      "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
      "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
      "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "EX: existential there\n",
      "    there\n",
      "FW: foreign word\n",
      "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
      "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
      "    terram fiche oui corporis ...\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "JJR: adjective, comparative\n",
      "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
      "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
      "    cozier creamier crunchier cuter ...\n",
      "JJS: adjective, superlative\n",
      "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
      "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
      "    dearest deepest densest dinkiest ...\n",
      "LS: list item marker\n",
      "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
      "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
      "    two\n",
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "PDT: pre-determiner\n",
      "    all both half many quite such sure this\n",
      "POS: genitive marker\n",
      "    ' 's\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "RBR: adverb, comparative\n",
      "    further gloomier grander graver greater grimmer harder harsher\n",
      "    healthier heavier higher however larger later leaner lengthier less-\n",
      "    perfectly lesser lonelier longer louder lower more ...\n",
      "RBS: adverb, superlative\n",
      "    best biggest bluntest earliest farthest first furthest hardest\n",
      "    heartiest highest largest least less most nearest second tightest worst\n",
      "RP: particle\n",
      "    aboard about across along apart around aside at away back before behind\n",
      "    by crop down ever fast for forth from go high i.e. in into just later\n",
      "    low more off on open out over per pie raising start teeth that through\n",
      "    under unto up up-pp upon whole with you\n",
      "SYM: symbol\n",
      "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "UH: interjection\n",
      "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
      "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
      "    man baby diddle hush sonuvabitch ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "WDT: WH-determiner\n",
      "    that what whatever which whichever\n",
      "WP: WH-pronoun\n",
      "    that what whatever whatsoever which who whom whosoever\n",
      "WP$: WH-pronoun, possessive\n",
      "    whose\n",
      "WRB: Wh-adverb\n",
      "    how however whence whenever where whereby whereever wherein whereof why\n",
      "``: opening quotation mark\n",
      "    ` ``\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"abcdefghijklmnopqrstuvwxyz'-./\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allowed_chars = string.ascii_lowercase + \"'\" + \"-\" + \".\" + \"/\"\n",
    "allowed_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spell = Speller(lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ']' does not match opening parenthesis '(' (4280761989.py, line 32)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[16], line 32\u001B[1;36m\u001B[0m\n\u001B[1;33m    [tokenize_and_preprocess(chatC1['anonymised'][i], False) for i in range(len(chatC1['anonymised'])]\u001B[0m\n\u001B[1;37m                                                                                                     ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m closing parenthesis ']' does not match opening parenthesis '('\n"
     ]
    }
   ],
   "source": [
    "def tokenize_and_preprocess(utt, stopwords=False):\n",
    "    res = []\n",
    "    contractions_removed = []\n",
    "    for word in utt.split():\n",
    "        contractions_removed.append(contractions.fix(word))\n",
    "    contractions_removed = ' '.join(contractions_removed)\n",
    "\n",
    "    for el in contractions_removed:\n",
    "        if el in list(punctuation):\n",
    "            contractions_removed = contractions_removed.replace(el, \" \")\n",
    "\n",
    "    for token in word_tokenize(contractions_removed):\n",
    "        token = token.lower()\n",
    "        if stopwords:\n",
    "            if token not in set(stoplist + list(punctuation)) and\\\n",
    "                re.search('[a-zA-Z]', token) and\\\n",
    "                all(char in allowed_chars for char in token):\n",
    "                token = spell(token)\n",
    "                res.append(token)\n",
    "        else:\n",
    "            if token not in list(punctuation) and\\\n",
    "                re.search('[a-zA-Z]', token) and\\\n",
    "                all(char in allowed_chars for char in token):\n",
    "                token = spell(token)\n",
    "                res.append(token)\n",
    "    return res\n",
    "[tokenize_and_preprocess(chatC1['anonymised'][i], False) for i in range(len(chatC1['anonymised']))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(['it', 's', 'true', 'that', 'they', 'are', 'still', 'there', 'now', 'so', 'present', 'simple', 'ok', 'but', 'especially', 'because', 'you', 'were', 'not', 'just', 'saying', 'that', 'but', 'you', 'were', 'saying', 'that', 'you', 'could', 'not', 'understand', 'them', 'so', 'this', 'is', 'more', 'specific', 'and', 'means', 'the', 'past', 'simple', 'would', 'be', 'better', 'really', 'by', 'the', 'way'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Get chat's Age of Acquisition values\n",
    "## return value: tuple(total, teacher, student)\n",
    "\n",
    "def chat_AoA(chat):\n",
    "    aoa_chat_total, aoa_chat_teacher, aoa_chat_student = 0, 0, 0\n",
    "\n",
    "    for index, utt in chat.iterrows():\n",
    "        utterance = utt['anonymised']\n",
    "        role = utt['role']\n",
    "        aoa_utt = 0\n",
    "        aoa_n_tokens = 0\n",
    "\n",
    "        utterance = utterance.replace('<STUDENT>', '')\n",
    "        utterance = utterance.replace('<TEACHER>', '')\n",
    "        tokens = tokenize_and_preprocess(utterance, True)\n",
    "\n",
    "        for token in tokens:\n",
    "            if token in AoA_list['Word'].values:\n",
    "                aoa_utt += AoA_list[AoA_list['Word'] == token]['AoA_Kup_lem'].item()\n",
    "                aoa_n_tokens += 1\n",
    "        aoa_utt = aoa_utt/aoa_n_tokens if aoa_n_tokens > 0 else aoa_utt\n",
    "        aoa_chat_total += aoa_utt\n",
    "\n",
    "        if role == 'teacher':\n",
    "            aoa_chat_teacher += aoa_utt\n",
    "        elif role == 'student':\n",
    "            aoa_chat_student += aoa_utt\n",
    "\n",
    "    aoa_chat_total /= len(chat['anonymised'])\n",
    "    aoa_chat_student /= len(chat[chat['role'].str.contains('student')])\n",
    "    aoa_chat_teacher /= len(chat[chat['role'].str.contains('teacher')])\n",
    "\n",
    "    return aoa_chat_total, aoa_chat_teacher, aoa_chat_student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Get chat's MLUs\n",
    "## return value: tuple(total, teacher, student)\n",
    "\n",
    "def chat_MLU(chat):\n",
    "    teacher_utt = chat[chat['role'].str.contains('teacher')]\n",
    "    student_utt = chat[chat['role'].str.contains('student')]\n",
    "\n",
    "    return (\n",
    "        np.mean(chat['nWords']),\n",
    "        np.mean(teacher_utt['nWords']),\n",
    "        np.mean(student_utt['nWords'])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "WF_list_billion = pd.read_csv('unigram_freq.csv/unigram_freq.csv')\n",
    "WF_list_billion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Get chat's Word Frequency values\n",
    "## return value: tuple(total, teacher, student, rare_total, rare_teacher, rare_student)\n",
    "\n",
    "def chat_WF(chat):\n",
    "    wf_chat_total, wf_chat_teacher, wf_chat_student = 0, 0, 0\n",
    "    tokens_total, tokens_teacher, tokens_student = 0, 0, 0\n",
    "    rare_total, rare_teacher, rare_student = 0, 0, 0\n",
    "    for index, utt in chat.iterrows():\n",
    "        utterance = utt['anonymised']\n",
    "        role = utt['role']\n",
    "        wf_utt = 0\n",
    "        wf_n_tokens = 0\n",
    "\n",
    "        utterance = utterance.replace('<STUDENT>', '')\n",
    "        utterance = utterance.replace('<TEACHER>', '')\n",
    "        tokens = tokenize_and_preprocess(utterance, True)\n",
    "\n",
    "        tokens_total += len(tokens)\n",
    "\n",
    "\n",
    "        for token in tokens:\n",
    "            if token in WF_list_billion['word'].values:\n",
    "                try:\n",
    "                    index = WF_list_billion.index[WF_list_billion['word'] == token].tolist()[0]\n",
    "                except:\n",
    "                    print(token)\n",
    "                wf_utt += index\n",
    "                wf_n_tokens += 1\n",
    "            else:\n",
    "                rare_total += 1\n",
    "                if role == 'teacher':\n",
    "                    rare_teacher += 1\n",
    "                elif role == 'student':\n",
    "                    rare_student += 1\n",
    "        wf_utt = wf_utt/wf_n_tokens if wf_n_tokens > 0 else wf_utt\n",
    "        wf_chat_total += wf_utt\n",
    "\n",
    "        if role == 'teacher':\n",
    "            wf_chat_teacher += wf_utt\n",
    "            tokens_teacher += len(tokens)\n",
    "        elif role == 'student':\n",
    "            wf_chat_student += wf_utt\n",
    "            tokens_student += len(tokens)\n",
    "\n",
    "    wf_chat_total /= len(chat['anonymised'])\n",
    "    wf_chat_student /= len(chat[chat['role'].str.contains('student')])\n",
    "    wf_chat_teacher /= len(chat[chat['role'].str.contains('teacher')])\n",
    "    return wf_chat_total, wf_chat_teacher, wf_chat_student, rare_total/tokens_total, rare_teacher/tokens_teacher, rare_student/tokens_student\n",
    "\n",
    "chat_WF(chatC1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''This is for the COCA corpus'''\n",
    "\n",
    "# ## Get chat's Word Frequency values\n",
    "# ## return value: tuple(total, teacher, student, rare_total, rare_teacher, rare_student)\n",
    "#\n",
    "# def chat_WF(chat):\n",
    "#     wf_chat_total, wf_chat_teacher, wf_chat_student = 0, 0, 0\n",
    "#     tokens_total, tokens_teacher, tokens_student = 0, 0, 0\n",
    "#     rare_total, rare_teacher, rare_student = 0, 0, 0\n",
    "#     for index, utt in chat.iterrows():\n",
    "#         utterance = utt['anonymised']\n",
    "#         role = utt['role']\n",
    "#         wf_utt = 0\n",
    "#         wf_n_tokens = 0\n",
    "#\n",
    "#         utterance = utterance.replace('<STUDENT>', '')\n",
    "#         utterance = utterance.replace('<TEACHER>', '')\n",
    "#         tokens = word_tokenize(utterance)\n",
    "#\n",
    "#         # we get rid of the stoplist words\n",
    "#         tokens = [token.lower() for token in tokens if token.lower() not in set(stoplist+list(punctuation)) and re.search('[a-zA-Z]', token) and all(char in string.ascii_lowercase + \"'\" + \"-\" + \".\" + \"/\" for char in token.lower())]\n",
    "#\n",
    "#         tokens_total += len(tokens)\n",
    "#\n",
    "#         predicted_tokens_classes = nltk.pos_tag(tokens)\n",
    "#\n",
    "#         for token, prediction in zip(tokens, predicted_tokens_classes):\n",
    "#             if token in WF_list['word'].values:\n",
    "#                 # print(token)\n",
    "#                 predicted_tag = prediction[1][0].lower()\n",
    "#                 # if len(WF_list.loc[WF_list['word'] == token]) == 1:\n",
    "#                 #     list_entry = WF_list.loc[WF_list['word'] == token]\n",
    "#                 # else:\n",
    "#                 #     list_entry =\n",
    "#                 list_entry = WF_list.loc[WF_list['word'] == token]\n",
    "#                 if len(list_entry) > 1:  # if more then one option, use the predicted tag\n",
    "#                     list_entry = list_entry[list_entry['PoS'] == predicted_tag]\n",
    "#                     if len(list_entry) > 1:\n",
    "#                         # specifically for \"found\" which returns two words with the same tag\n",
    "#                         if prediction == 'VBN':\n",
    "#                             list_entry = list_entry.head(1) # past form of 'find'\n",
    "#                         else:\n",
    "#                             list_entry = list_entry.iloc[[1]] # the verb 'found'\n",
    "#                 if len(list_entry) == 0:  # if the predicted tag is wrong, use the most frequent version\n",
    "#                     list_entry = WF_list.loc[WF_list['word'] == token].head(1)\n",
    "#                 # print(token)\n",
    "#                 # print(list_entry['lemFreq'].item())\n",
    "#                 try:\n",
    "#                     wf_utt += list_entry['lemRank'].item()\n",
    "#                 except ValueError:\n",
    "#                     print(f\"Token: {token}\\nNLTK Prediction: {prediction}\\nList entry: {list_entry}\\nList entry before: {WF_list.loc[WF_list['word'] == token]}\\nList entry top: {WF_list.loc[WF_list['word'] == token].head(1)}\")\n",
    "#\n",
    "#                 wf_n_tokens += 1\n",
    "#             else:\n",
    "#                 rare_total += 1\n",
    "#                 # print(token, 'not in list')\n",
    "#                 if role == 'teacher':\n",
    "#                     rare_teacher += 1\n",
    "#                 elif role == 'student':\n",
    "#                     rare_student += 1\n",
    "#         wf_utt = wf_utt/wf_n_tokens if wf_n_tokens > 0 else wf_utt\n",
    "#         wf_chat_total += wf_utt\n",
    "#\n",
    "#         if role == 'teacher':\n",
    "#             wf_chat_teacher += wf_utt\n",
    "#             tokens_teacher += len(tokens)\n",
    "#         elif role == 'student':\n",
    "#             wf_chat_student += wf_utt\n",
    "#             tokens_student += len(tokens)\n",
    "#\n",
    "#     wf_chat_total /= len(chat['anonymised'])\n",
    "#     wf_chat_student /= len(chat[chat['role'].str.contains('student')])\n",
    "#     wf_chat_teacher /= len(chat[chat['role'].str.contains('teacher')])\n",
    "#     return wf_chat_total, wf_chat_teacher, wf_chat_student, rare_total/tokens_total, rare_teacher/tokens_teacher, rare_student/tokens_student\n",
    "#\n",
    "# chat_WF(chatC1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Get chat's Type-Token ratio values\n",
    "## return value: tuple(total, teacher, student)\n",
    "\n",
    "def chat_TTR(chat):\n",
    "    token_list_student = []\n",
    "    token_list_teacher = []\n",
    "\n",
    "    for index, utt in chat.iterrows():\n",
    "        utterance = utt['anonymised']\n",
    "        role = utt['role']\n",
    "\n",
    "        utterance = utterance.replace('<STUDENT>', '')\n",
    "        utterance = utterance.replace('<TEACHER>', '')\n",
    "\n",
    "        word_tokens = tokenize_and_preprocess(utterance, False)\n",
    "        if role == 'teacher':\n",
    "            token_list_teacher += word_tokens\n",
    "        elif role == 'student':\n",
    "            token_list_student += word_tokens\n",
    "\n",
    "    return (\n",
    "        (len(set(token_list_teacher)) + len(set(token_list_student)))/(len(token_list_teacher) + len(token_list_student)),\n",
    "        len(set(token_list_teacher))/len(token_list_teacher),\n",
    "        len(set(token_list_student))/len(token_list_student)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def chat_utterance_proportion(chat):\n",
    "    return len(chat[chat['role'].str.contains('student')])/len(chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def chat_words_proportion(chat):\n",
    "    return np.sum((chat[chat['role'].str.contains('student')]['nWords']))/np.sum(chat['nWords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_student_timegaps(student, contents):\n",
    "    first_class_time = datetime.strptime(contents['start.time'].iloc[0], \"%Y-%m-%d %H:%M:%S\")\n",
    "    last = first_class_time\n",
    "    gaps = []\n",
    "    for class_time in contents['start.time'][1:]:\n",
    "        date_class_time = datetime.strptime(class_time, \"%Y-%m-%d %H:%M:%S\")\n",
    "        gaps.append((date_class_time-last).days)\n",
    "        last = date_class_time\n",
    "    return gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Now, I analyse progress of particular students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calc_scaffolding_proportion(chat):\n",
    "    chat_dropped = chat.dropna(subset=['seq.type'])\n",
    "    chat_dropped = chat_dropped[chat_dropped['role'].str.contains('teacher')]\n",
    "\n",
    "    return len(chat_dropped[chat_dropped['seq.type'].str.contains('scaffolding')])/len(chat[chat['role'].str.contains('teacher')])\n",
    "\n",
    "calc_scaffolding_proportion(chatC1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "students_progress = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "students_progress = json.load(open('progress_students.txt'))\n",
    "students_progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chatrooms_dropped = chatrooms_all.dropna(subset=['seq.type'])\n",
    "\n",
    "scaffolding_utts = chatrooms_dropped[chatrooms_dropped['seq.type'].str.contains('scaffolding')]\n",
    "scaffolding_utts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preceding_turns_scaff = chatrooms_all.iloc[scaffolding_utts.index-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def chat_flesch_kincaid(chat):\n",
    "    teacher_all, student_all = \"\", \"\"\n",
    "    for index, utt in chat.iterrows():\n",
    "        utterance = utt['anonymised']\n",
    "        if len(word_tokenize(utterance)) < 3:  # Discarding utts like \"ok\", \"hi\"\n",
    "            continue\n",
    "        role = utt['role']\n",
    "\n",
    "        utterance = utterance.replace('<STUDENT>', '')\n",
    "        utterance = utterance.replace('<TEACHER>', '')\n",
    "        if utterance[-1:] not in ('.', '!', '?'):\n",
    "            utterance += '.'  # finish all utts in full stops\n",
    "\n",
    "        if role == 'teacher':\n",
    "            teacher_all += ' ' + utterance\n",
    "        elif role == 'student':\n",
    "            student_all += ' ' + utterance\n",
    "\n",
    "    fk_total = Readability(teacher_all+student_all).flesch_kincaid().score if len(tokenize_and_preprocess(teacher_all+student_all)) >= 100 else 0\n",
    "    fk_teacher = Readability(teacher_all).flesch_kincaid().score if len(tokenize_and_preprocess(teacher_all)) >= 100 else 0\n",
    "    fk_student = Readability(student_all).flesch_kincaid().score if len(tokenize_and_preprocess(student_all)) >= 100 else 0\n",
    "\n",
    "    return fk_total, fk_teacher, fk_student\n",
    "chat_flesch_kincaid(chatC1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def chat_flesch(chat):\n",
    "    teacher_all, student_all = \"\", \"\"\n",
    "    for index, utt in chat.iterrows():\n",
    "        utterance = utt['anonymised']\n",
    "        if len(word_tokenize(utterance)) < 3:  # Discarding utts like \"ok\", \"hi\"\n",
    "            continue\n",
    "        role = utt['role']\n",
    "\n",
    "        utterance = utterance.replace('<STUDENT>', '')\n",
    "        utterance = utterance.replace('<TEACHER>', '')\n",
    "        if utterance[-1:] not in ('.', '!', '?'):\n",
    "            utterance += '.'  # finish all utts in full stops\n",
    "        # print(utterance)\n",
    "\n",
    "        if role == 'teacher':\n",
    "            teacher_all += ' ' + utterance\n",
    "        elif role == 'student':\n",
    "            student_all += ' ' + utterance\n",
    "\n",
    "    # print(student_all)\n",
    "    flesch_total = Readability(teacher_all+student_all).flesch().score if len(tokenize_and_preprocess(teacher_all+student_all)) >= 100 else 0\n",
    "    flesch_teacher = Readability(teacher_all).flesch().score if len(tokenize_and_preprocess(teacher_all)) >= 100 else 0\n",
    "    flesch_student = Readability(student_all).flesch().score if len(tokenize_and_preprocess(student_all)) >= 100 else 0\n",
    "\n",
    "    return flesch_total, flesch_teacher, flesch_student\n",
    "chat_flesch(chatC1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def chat_gunning_fog(chat):\n",
    "    teacher_all, student_all = \"\", \"\"\n",
    "    for index, utt in chat.iterrows():\n",
    "        utterance = utt['anonymised']\n",
    "        if len(word_tokenize(utterance)) < 3:  # Discarding utts like \"ok\", \"hi\"\n",
    "            continue\n",
    "        role = utt['role']\n",
    "\n",
    "        utterance = utterance.replace('<STUDENT>', '')\n",
    "        utterance = utterance.replace('<TEACHER>', '')\n",
    "        if utterance[-1:] not in ('.', '!', '?'):\n",
    "            utterance += '.'  # finish all utts in full stops\n",
    "        # print(utterance)\n",
    "\n",
    "        if role == 'teacher':\n",
    "            teacher_all += ' ' + utterance\n",
    "        elif role == 'student':\n",
    "            student_all += ' ' + utterance\n",
    "\n",
    "    # print(student_all)\n",
    "    gf_total = Readability(teacher_all+student_all).gunning_fog().score if len(tokenize_and_preprocess(teacher_all+student_all)) >= 100 else 0\n",
    "    gf_teacher = Readability(teacher_all).gunning_fog().score if len(tokenize_and_preprocess(teacher_all)) >= 100 else 0\n",
    "    gf_student = Readability(student_all).gunning_fog().score if len(tokenize_and_preprocess(student_all)) >= 100 else 0\n",
    "\n",
    "    return gf_total, gf_teacher, gf_student\n",
    "chat_gunning_fog(chatC1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_turns(chat):\n",
    "    turns = {\n",
    "        'turn': [],\n",
    "        'speaker': []\n",
    "    }\n",
    "    curr_turn = \"\"\n",
    "    curr_speaker = chat['role'][0]\n",
    "    for index, utt in chat.iterrows():\n",
    "        if utt['role'] != curr_speaker:\n",
    "            turns['turn'].append(curr_turn)\n",
    "            turns['speaker'].append(curr_speaker)\n",
    "            curr_turn = \"\"  # reset when new speaker is speaking\n",
    "\n",
    "        curr_turn += utt['anonymised']\n",
    "        if curr_turn[-1] not in ('.', '!', '?'):\n",
    "            curr_turn += '.'\n",
    "        curr_turn += ' '\n",
    "\n",
    "        curr_speaker = utt['role']\n",
    "\n",
    "    # add the last utterance\n",
    "    turns['turn'].append(curr_turn)\n",
    "    turns['speaker'].append(curr_speaker)   \n",
    "    \n",
    "    return pd.DataFrame.from_dict(turns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "get_turns(chatC1)[69:71]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_utt = chatC1.loc[94:96, ['anonymised', 'role']]\n",
    "ex_utt.columns = ['utterance','speaker']\n",
    "ex_utt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def teacher_student_utt_pairs(chat):\n",
    "    teacher_utts = chat.loc[chat['role'] == 'teacher']\n",
    "    teacher_utts = teacher_utts.drop(teacher_utts[teacher_utts['turn.number'] == 1].index)\n",
    "\n",
    "    previous_utts = pd.DataFrame(columns=list(teacher_utts.columns))\n",
    "    for index, utt in teacher_utts.iterrows():\n",
    "        if isinstance((utt['responding.to']), float): # still wrong\n",
    "            if not math.isnan(utt['responding.to']):\n",
    "                # print('res')\n",
    "                previous_utts = pd.concat(\n",
    "                    [previous_utts, pd.DataFrame(chat.loc[chat['turn.number'] == utt['responding.to']])]\n",
    "                )\n",
    "            else:\n",
    "                turn_number = int(utt['turn.number'])-1\n",
    "                # print(turn_number)\n",
    "                while turn_number > 0 and turn_number in chat['turn.number'].values and not chat.loc[chat['turn.number'] == turn_number]['role'].values[0] == 'student':\n",
    "                    turn_number -= 1\n",
    "                if turn_number == 0:\n",
    "                    continue\n",
    "                previous_utts = pd.concat(\n",
    "                    [previous_utts, pd.DataFrame(chat.loc[chat['turn.number'] == turn_number])]\n",
    "                )\n",
    "\n",
    "    return teacher_utts, previous_utts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_student_utt_pairs(chatC1)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "teacher_student_utt_pairs(chatC1)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def total_utt_pairs(chat):\n",
    "    current_utts = chat[1:] # discarding the first utt\n",
    "    previous_utts = pd.DataFrame(columns=list(chat.columns))\n",
    "\n",
    "    for index, utt in current_utts.iterrows():\n",
    "        role = utt['role']\n",
    "        if isinstance(utt['responding.to'], float):\n",
    "            if not math.isnan(utt['responding.to']):\n",
    "                # print('res')\n",
    "                previous_utts = pd.concat(\n",
    "                    [previous_utts, pd.DataFrame(chat.loc[chat['turn.number'] == utt['responding.to']])]\n",
    "                )\n",
    "            else:\n",
    "                turn_number = int(utt['turn.number'])-1\n",
    "                # print(turn_number)\n",
    "                while turn_number > 0 and turn_number in chat['turn.number'].values and chat.loc[chat['turn.number'] == turn_number]['role'].values[0] == role:\n",
    "                    turn_number -= 1\n",
    "                if turn_number == 0:\n",
    "                    continue\n",
    "                previous_utts = pd.concat(\n",
    "                    [previous_utts, pd.DataFrame(chat.loc[chat['turn.number'] == turn_number])]\n",
    "                )\n",
    "\n",
    "    return current_utts, previous_utts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance((chatC1['responding.to'].values[0]), float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatC1['responding.to'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "total_utt_pairs(chatC1)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "total_utt_pairs(chatC1)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tutor_overlaps_chat(chat):\n",
    "    overlaps = []\n",
    "    teacher_utts, previous_utts = teacher_student_utt_pairs(chat)\n",
    "\n",
    "    for (utt, previous) in zip(teacher_utts['anonymised'], previous_utts['anonymised']):\n",
    "        tokens = tokenize_and_preprocess(utt, True)\n",
    "        previous_tokens = tokenize_and_preprocess(previous, True)\n",
    "\n",
    "        intersect = set(previous_tokens).intersection(set(tokens))\n",
    "        union = set(previous_tokens).union(set(tokens))\n",
    "        \n",
    "        if len(union) > 0:\n",
    "            overlaps.append(len(intersect)/len(union))  # jaccard\n",
    "\n",
    "    return np.mean(overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tutor_overlaps_chat(chatC1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def total_overlaps_chat(chat):\n",
    "    overlaps = []\n",
    "    current_utts, previous_utts = total_utt_pairs(chat)\n",
    "\n",
    "    for (utt, previous) in zip(current_utts['anonymised'], previous_utts['anonymised']):\n",
    "        tokens = tokenize_and_preprocess(utt, True)\n",
    "        previous_tokens = tokenize_and_preprocess(previous, True)\n",
    "        \n",
    "        intersect = set(previous_tokens).intersection(set(tokens))\n",
    "        union = set(previous_tokens).union(set(tokens))\n",
    "        \n",
    "        if len(union) > 0:\n",
    "            overlaps.append(len(intersect)/len(union))  # jaccard\n",
    "\n",
    "    return np.mean(overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "total_overlaps_chat(chatC1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tutor_overlaps_turns_chat(chat):\n",
    "    overlaps = []\n",
    "    chat_turns = get_turns(chat)\n",
    "    prev_student = ''\n",
    "    for index, row in chat_turns.iterrows():\n",
    "        if row['speaker'] == 'student':\n",
    "            prev_student = row['turn']\n",
    "        elif prev_student:\n",
    "            student_tokens = set(tokenize_and_preprocess(prev_student, True))\n",
    "            teacher_tokens = set(tokenize_and_preprocess(row['turn'], True))\n",
    "            \n",
    "            intersect = student_tokens.intersection(teacher_tokens)\n",
    "            union = student_tokens.union(teacher_tokens)\n",
    "            \n",
    "            if len(union) > 0:\n",
    "                overlaps.append(len(intersect)/len(union))  # jaccard\n",
    "\n",
    "    return np.mean(overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tutor_overlaps_turns_chat(chatC1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def either_overlaps_turns_chat(chat):\n",
    "    overlaps = []\n",
    "    chat_turns = get_turns(chat)\n",
    "    prev_turn = chat_turns['turn'][0]\n",
    "    for index, row in chat_turns[1:].iterrows():\n",
    "        prev_tokens = set(tokenize_and_preprocess(prev_turn, True))\n",
    "        curr_tokens = set(tokenize_and_preprocess(row['turn'], True))\n",
    "\n",
    "        intersect = prev_tokens.intersection(curr_tokens)\n",
    "        union = prev_tokens.union(curr_tokens)\n",
    "        \n",
    "        if len(union) > 0:\n",
    "            overlaps.append(len(intersect)/len(union))  # jaccard\n",
    "            \n",
    "        prev_turn = row['turn']\n",
    "\n",
    "    return np.mean(overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "either_overlaps_turns_chat(chatC1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pos_overlap_chat(chat):  # how many pos were repeated from the prev utterance\n",
    "    overlaps = []\n",
    "    chat_turns = get_turns(chat)\n",
    "    prev_turn = chat_turns['turn'][0]\n",
    "    for index, row in chat_turns[1:].iterrows():\n",
    "        prev_tokens = tokenize_and_preprocess(prev_turn)\n",
    "        curr_tokens = tokenize_and_preprocess(row['turn'])\n",
    "        \n",
    "        prev_pos = set([tag for word, tag in nltk.pos_tag(prev_tokens)])\n",
    "        curr_pos = set([tag for word, tag in nltk.pos_tag(curr_tokens)])\n",
    "\n",
    "        intersect = prev_pos.intersection(curr_pos)\n",
    "        union = prev_pos.union(curr_pos)\n",
    "        \n",
    "        if len(union) > 0:\n",
    "            overlaps.append(len(intersect)/len(union))  # jaccard\n",
    "            \n",
    "        prev_turn = row['turn']\n",
    "\n",
    "    return np.mean(overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pos_overlap_chat(chatC1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It only takes into account how similar the tutor's and teacher's grades are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_complexity_matching_MLU(chat):\n",
    "    mlu_scores = chat_MLU(chat)\n",
    "    diff = mlu_scores[1]-mlu_scores[2]\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_complexity_matching_MLU(chatrooms[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_complexity_matching_AoA(chat):\n",
    "    AoA_scores = chat_AoA(chat)\n",
    "    diff = AoA_scores[1]-AoA_scores[2]\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_complexity_matching_AoA(chatrooms[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}